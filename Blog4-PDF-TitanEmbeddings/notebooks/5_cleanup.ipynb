{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62237d5-eb33-48e6-b661-c3282d636bb8",
   "metadata": {},
   "source": [
    "## Clean up the OpenSearch Indexes/S3 bucket to Rerun this solution with new data\n",
    "---\n",
    "\n",
    "1. This notebook cleans the indexes created in OpenSearch Serverless and the content in the S3 bucket\n",
    "\n",
    "1. Run this step if you want to run the entire solution with new data from the scratch, no need to clean the content in the console manually\n",
    "\n",
    "Set this step to `yes` in the [config.yaml](config.yaml) file to clean up the content after the run. Keep it set to `no` if you want to re run the solution with the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f405d71-ec59-4401-bd78-614b2ed7ff6e",
   "metadata": {},
   "source": [
    "***Delete the CFT stack to clean up all the resources that are created in your account manually from the CloudFormation console. This notebook only deletes the S3 folders containing pre existing images and texts, and the indexes created in OpenSearch. This is for users to re run this solution with new indexes, new embeddings and new data stored in S3***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd8420-1ef1-456c-8516-bd94ed7761b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install the requirements before running this notebook\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9950a46-3640-4991-9d36-6506ba19e450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the libraries that are needed to run this notebook\n",
    "import os\n",
    "import re\n",
    "import ray\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import botocore\n",
    "import sagemaker\n",
    "import globals as g\n",
    "from typing import List\n",
    "from requests_auth_aws_sigv4 import AWSSigV4\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from utils import get_cfn_outputs, get_bucket_name, download_image_files_from_s3, get_text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b3ab8-0493-4f36-bc93-789aa8cb8ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set a logger\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc5781-7d14-4a22-9c96-6c061e8c14e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "CONFIG_FILE_PATH = \"config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d90b2-7c2b-49e5-a120-7cc5db1ef1b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a5d15-2f7f-4127-9b30-e83a936b7112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name: str = get_bucket_name(config['aws']['cfn_stack_name'])\n",
    "logger.info(f\"Bucket name being used to store extracted images and texts from data: {bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7526a94-fc49-4820-a947-9159338da88f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = get_cfn_outputs(config['aws']['cfn_stack_name'])\n",
    "host = outputs['MultimodalCollectionEndpoint'].split('//')[1]\n",
    "text_index_name = outputs['OpenSearchTextIndexName']\n",
    "img_index_name = outputs['OpenSearchImgIndexName']\n",
    "logger.info(f\"opensearchhost={host}, text index={text_index_name}, image index={img_index_name}\")\n",
    "osi_text_endpoint = f\"https://{outputs['OpenSearchPipelineTextEndpoint']}/data/ingest\"\n",
    "osi_img_endpoint = f\"https://{outputs['OpenSearchPipelineImgEndpoint']}/data/ingest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb528147-1c12-420a-ab00-962bd48e2716",
   "metadata": {},
   "source": [
    "### Clean up the indexes and the images/texts in the S3 bucket\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de876967-4f40-48a4-b22e-77dc584df454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, config['aws']['region'], g.OS_SERVICE)\n",
    "\n",
    "# Represents the OSI client for images\n",
    "img_os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")\n",
    "\n",
    "# Represents the OSI client for texts\n",
    "text_os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae101d-c299-45fe-b8cd-9c22544bc003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete the text and image indexes created in the opensearch serveless collection\n",
    "try:\n",
    "    # Check if the image index exists\n",
    "    if img_os_client.indices.exists(img_index_name):\n",
    "        img_response = img_os_client.indices.delete(img_index_name)\n",
    "        logger.info(f\"response received for the create index for images -> {img_response}\")\n",
    "    else:\n",
    "        logger.info(f\"The image index '{img_index_name}' does not exist and cannot be deleted.\")\n",
    "\n",
    "    # Check if the text index exists\n",
    "    if text_os_client.indices.exists(text_index_name):\n",
    "        txt_response = text_os_client.indices.delete(text_index_name)\n",
    "        logger.info(f\"response received for the create index for texts -> {txt_response}\")\n",
    "    else:\n",
    "        logger.info(f\"The text index '{text_index_name}' does not exist and cannot be deleted.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in deleting index, exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4aa70-e97c-4a59-b294-20440430a026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up the image and text folders in the S3 bucket\n",
    "def clean_up_s3_folders(bucket_name: str, prefixes: List[str]):\n",
    "    \"\"\"\n",
    "    This function takes in a list of prefixes and deletes those folders\n",
    "    \"\"\"\n",
    "    client = boto3.client('s3')\n",
    "    for prefix in prefixes:\n",
    "        response = client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "        obj_list = [{'Key': obj['Key']} for obj in response.get('Contents', [])]\n",
    "        if obj_list:\n",
    "            delete_response = client.delete_objects(\n",
    "                Bucket=bucket_name,\n",
    "                Delete={'Objects': obj_list}\n",
    "            )\n",
    "            logger.info(f'Deleted objects from {prefix}:', delete_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33694166-a34d-40aa-baa6-04197bf61bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete the text and image folders from the s3 bucket\n",
    "prefixes = [g.BUCKET_IMG_PREFIX, g.BUCKET_PDF_TEXT_PREFIX]\n",
    "clean_up_s3_folders(bucket_name, prefixes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
