{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbb582e-d21a-41cf-b45e-e2f462424ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data ingestion\n",
    "\n",
    "***This notebook works best with the `conda_python3` on the `ml.t3.xlarge` instance***.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we download the images corresponding to the slide deck that we uploaded into Amazon S3 in the [1_data_prep.ipynb](./1_data_prep) notebook, convert them into embeddings and then ingest these embeddings into a vector database i.e. [Amazon OpenSearch Service Serverless](https://aws.amazon.com/opensearch-service/features/serverless/).\n",
    "\n",
    "1. We use the [Anthropicâ€™s Claude 3 Sonnet foundation model](https://aws.amazon.com/about-aws/whats-new/2024/03/anthropics-claude-3-sonnet-model-amazon-bedrock/) available on Bedrock to convert image to text.\n",
    "\n",
    "1. We then use [Amazon Titan Text Embeddings](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html) model to convert the text into embeddings.\n",
    "\n",
    "1. The embeddings are then ingested into OpenSearch Service Serverless using the [Amazon OpenSearch Ingestion](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/ingestion.html) pipeline. We ingest the embeddings into an OpenSearch Serverless index via the OpenSearch Ingestion API.\n",
    "\n",
    "1. The OpenSearch Service Serverless Collection is created via the AWS CloudFormation stack for this blog post.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a62857-6a66-44db-9d92-3df221c6bd21",
   "metadata": {},
   "source": [
    "## Step 1. Setup\n",
    "\n",
    "Install the required Python packages and import the relevant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f869e5d-8e4b-4d44-9e2a-4f20b77b92d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda5d30-06f7-44a6-9b1d-8ac27fb93cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the libraries that are needed to run this notebook\n",
    "import os\n",
    "import re\n",
    "import ray\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import nltk\n",
    "import boto3\n",
    "import codecs\n",
    "import base64\n",
    "import logging\n",
    "import requests\n",
    "import botocore\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import globals as g\n",
    "from pathlib import Path\n",
    "from nltk.tag import pos_tag\n",
    "from typing import List, Dict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from requests_auth_aws_sigv4 import AWSSigV4\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from utils import get_cfn_outputs, get_bucket_name, download_image_files_from_s3, get_text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e79b34-a7ee-4bfc-a7e0-109ef54426f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set a logger\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038bd7c-4e59-435b-80fc-c3a3ae928c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=g.AWS_REGION, endpoint_url=g.TITAN_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c58b5c-8f93-4746-bcdd-5a9aafb4c3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "module_path=os.getcwd()\n",
    "g.__path__=module_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534bbced-2937-4ecd-945d-ca380f94a456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "# ray.init(runtime_env={\"working_dir\": \"./\"})\n",
    "ray.init()\n",
    "# ray.init(num_cpus=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcac8a-e241-4710-8499-0e834cf2df67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "CONFIG_FILE_PATH = \"config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7153438-f58d-4f63-b04e-1f8a5a02fc71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0911a8-d5d5-4f11-a749-a431d5bd6d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# endpoint_url=g.TITAN_URL\n",
    "region: str = config['aws']['region']\n",
    "endpoint_url: str = config['bedrock_model_info']['bedrock_ep_url'].format(region=region)\n",
    "claude_model_id: str = config['bedrock_model_info']['claude_sonnet_model_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9ddf2-d8f5-404a-8fcf-a5efa3f3fad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name: str = get_bucket_name(config['aws']['cfn_stack_name'])\n",
    "logger.info(f\"Bucket name being used to store extracted images and texts from data: {bucket_name}\")\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d273a8-4d5a-4ede-bc3f-b7d9c8fe6825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "sm_client = sagemaker_session.sagemaker_client\n",
    "sm_runtime_client = sagemaker_session.sagemaker_runtime_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba8ccd-7e5e-48c5-93fd-2a98319f33c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = get_cfn_outputs(config['aws']['cfn_stack_name'])\n",
    "host = outputs['MultimodalCollectionEndpoint'].split('//')[1]\n",
    "text_index_name = outputs['OpenSearchTextIndexName']\n",
    "img_index_name = outputs['OpenSearchImgIndexName']\n",
    "logger.info(f\"opensearchhost={host}, text index={text_index_name}, image index={img_index_name}\")\n",
    "osi_text_endpoint = f\"https://{outputs['OpenSearchPipelineTextEndpoint']}/data/ingest\"\n",
    "osi_img_endpoint = f\"https://{outputs['OpenSearchPipelineImgEndpoint']}/data/ingest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9213968-f87b-4e19-9d4d-99d0ab8f19d6",
   "metadata": {},
   "source": [
    "We use the OpenSearch client to create an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95923df7-fe11-4ace-ba2a-f56edf0ac1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, g.AWS_REGION, g.OS_SERVICE)\n",
    "\n",
    "# Represents the OSI client for images\n",
    "img_os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")\n",
    "\n",
    "# Represents the OSI client for images\n",
    "text_os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921892a-e599-490b-bd91-accc5cdb5f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_body = \"\"\"\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index.knn\": true\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"vector_embedding\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 1536,\n",
    "        \"method\": {\n",
    "          \"name\": \"hnsw\",\n",
    "          \"engine\": \"nmslib\",\n",
    "          \"parameters\": {}\n",
    "        }\n",
    "      },\n",
    "      \"file_path\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"file_text\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"page_number\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"metadata\": {\n",
    "        \"properties\": {\n",
    "          \"filename\": {\n",
    "            \"type\": \"text\"\n",
    "          },\n",
    "          \"entities\": {\n",
    "            \"type\": \"keyword\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# We would get an index already exists exception if the index already exists, and that is fine.\n",
    "index_body = json.loads(index_body)\n",
    "try:\n",
    "    # Check if the image index exists\n",
    "    if not img_os_client.indices.exists(img_index_name):\n",
    "        img_response = img_os_client.indices.create(img_index_name, body=index_body)\n",
    "        logger.info(f\"response received for the create index for images -> {img_response}\")\n",
    "    else:\n",
    "        logger.info(f\"The image index '{img_index_name}' already exists.\")\n",
    "\n",
    "    # Check if the text index exists\n",
    "    if not text_os_client.indices.exists(text_index_name):\n",
    "        txt_response = text_os_client.indices.create(text_index_name, body=index_body)\n",
    "        logger.info(f\"response received for the create index for texts -> {txt_response}\")\n",
    "    else:\n",
    "        logger.info(f\"The text index '{text_index_name}' already exists.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in creating index, exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369078c2-94b1-4510-940a-78e6b029e506",
   "metadata": {},
   "source": [
    "## Step 2. Download the images files from S3 and convert to Base64\n",
    "\n",
    "Now we download the image files from the S3 bucket. Once downloaded these files are converted into [Base64](https://en.wikipedia.org/wiki/Base64) encoding so that we can create embeddings from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d0ec15-3aca-41d9-a4b1-4b6dde4a2f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(g.PDF_IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(g.PDF_TEXT_DIR, exist_ok=True)\n",
    "if config['content_info']['content_type'] == 'pdf':\n",
    "    # download images from S3, we would be converting these to embeddings\n",
    "    image_files: List = download_image_files_from_s3(bucket_name, g.BUCKET_IMG_PREFIX, g.PDF_IMAGE_DIR, g.IMAGE_FILE_EXTN)\n",
    "    text_files: List = download_image_files_from_s3(bucket_name, g.BUCKET_PDF_TEXT_PREFIX, g.PDF_TEXT_DIR, g.TEXT_FILE_EXTN)\n",
    "    logger.info(f\"downloaded {len(image_files) + len(text_files)} files from s3\")\n",
    "elif config['content_info']['content_type'] == 'slide_deck':\n",
    "    # download images from S3, we would be converting these to embeddings\n",
    "    image_files: List = download_image_files_from_s3(bucket_name, g.BUCKET_IMG_PREFIX, g.IMAGE_DIR, g.IMAGE_FILE_EXTN)\n",
    "    logger.info(f\"downloaded {len(image_files)} from s3\")\n",
    "else:\n",
    "    logger.error(f\"No content type provided. Must be either a 'pdf' or a 'slide_deck'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70833d4-b585-477b-93ec-5556c994b9ba",
   "metadata": {},
   "source": [
    "#### Convert jpg files into Base64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c8f80-d457-46d5-9d20-f1ca8ebe106b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_file_path: str) -> str:\n",
    "    with open(image_file_path, \"rb\") as image_file:\n",
    "        b64_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "        b64_image_path = os.path.join(g.B64_ENCODED_IMAGES_DIR, f\"{Path(image_file_path).stem}.b64\")\n",
    "        with open(b64_image_path, \"wb\") as b64_image_file:\n",
    "            b64_image_file.write(bytes(b64_image, 'utf-8'))\n",
    "    return b64_image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d70875-7b8b-44ff-bb5a-0f8b9e43adca",
   "metadata": {},
   "source": [
    "## Step 3. Get embeddings for the base64 encoded images\n",
    "\n",
    "Now we are ready to use Amazon Bedrock via the  Anthropicâ€™s Claude 3 Sonnet foundation model and Amazon Titan Text Embeddings model to convert the base64 version of the images into embeddings. We ingest embeddings into the pipeline using the [requests](https://pypi.org/project/requests/) HTTP library\n",
    "\n",
    "You must sign all HTTP requests to the pipeline using [Signature Version 4](https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0ed32-9e7f-448b-93d5-ef0e65404f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img_desc(image_file_path: str, prompt: str):\n",
    "    # bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=g.AWS_REGION, endpoint_url=g.TITAN_URL)\n",
    "    bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=region, endpoint_url=endpoint_url)\n",
    "    # read the file, MAX image size supported is 2048 * 2048 pixels\n",
    "    with open(image_file_path, \"rb\") as image_file:\n",
    "        input_image_b64 = image_file.read().decode('utf-8')\n",
    "\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1000,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": input_image_b64\n",
    "                            },\n",
    "                        },\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=claude_model_id,\n",
    "        body=body\n",
    "    )\n",
    "\n",
    "    resp_body = json.loads(response['body'].read().decode(\"utf-8\"))\n",
    "    resp_text = resp_body['content'][0]['text'].replace('\"', \"'\")\n",
    "\n",
    "    return resp_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcf7db4-5d1f-4b12-99ec-a5484cc55036",
   "metadata": {},
   "source": [
    "### Download image files from S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d6845-1dc7-4d47-b296-d717a25d2494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['content_info']['content_type'] == 'pdf':\n",
    "    # this is for the pdf file images\n",
    "    image_files: List = download_image_files_from_s3(bucket_name, g.BUCKET_IMG_PREFIX, g.PDF_IMAGE_DIR, g.IMAGE_FILE_EXTN)\n",
    "    logger.info(f\"downloaded {len(image_files)} from s3\")\n",
    "elif config['content_info']['content_type'] == 'slide_deck':\n",
    "    # download images from S3, we would be converting these to embeddings\n",
    "    image_files: List = download_image_files_from_s3(bucket_name, g.BUCKET_IMG_PREFIX, g.IMAGE_DIR, g.IMAGE_FILE_EXTN)\n",
    "    logger.info(f\"downloaded {len(image_files)} from s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67111d9-359d-46fe-997e-cbb8e5f7992f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(g.B64_ENCODED_IMAGES_DIR, exist_ok=True)\n",
    "if config['content_info']['content_type'] == 'pdf':\n",
    "    file_list: List = glob.glob(os.path.join(g.PDF_IMAGE_DIR, f\"*{g.IMAGE_FILE_EXTN}\"))\n",
    "    logger.info(f\"there are {len(file_list)} pdf image files in the {g.PDF_IMAGE_DIR} directory for conversion to base64\")\n",
    "elif config['content_info']['content_type'] == 'slide_deck':\n",
    "    file_list: List = glob.glob(os.path.join(g.IMAGE_DIR, f\"*{g.IMAGE_FILE_EXTN}\"))\n",
    "    logger.info(f\"there are {len(file_list)} files in the {g.IMAGE_DIR} directory for conversion to base64\")\n",
    "\n",
    "# convert each file to base64 and store the base64 in a new file\n",
    "b64_image_file_list = list(map(encode_image_to_base64, file_list))\n",
    "logger.info(f\"base64 conversion done, there are {len(b64_image_file_list)} base64 encoded files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1431afe-11b1-4c88-bee1-78e9aeac0f8e",
   "metadata": {},
   "source": [
    "### Download text files from S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418a859-5381-45e3-a36e-e4cdcf362a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['content_info']['content_type'] == 'pdf':\n",
    "    # this is for the pdf file images\n",
    "    image_files: List = download_image_files_from_s3(bucket_name, g.BUCKET_PDF_TEXT_PREFIX, g.PDF_TEXT_DIR, g.TEXT_FILE_EXTN)\n",
    "    logger.info(f\"downloaded {len(image_files)} text files from s3\")\n",
    "else:\n",
    "    logger.error(f\"No text files extracted from the content given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fa6d7-1291-4fed-a75a-cb6f225208bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please provide a detailed description of the image. Describe the overall layout and design of the image. Identify and describe any tables, charts, or other visual elements present, including the specific data or information contained within them. Provide as much detail as possible about the content and format of the image. Your response should be extremely detailed and data oriented. Give the description for all four portions of the image, the upper right, upper left, lower right and lower left and include all key points data in each if possible. Be completely accurate.\n",
    "\"\"\"\n",
    "\n",
    "logger.info(f\"prompt used to get image description: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe56b3-b7e6-4012-b432-18289085ec55",
   "metadata": {},
   "source": [
    "### Hybrid Search: Extract Entities from the image, and prefilter the image description with those entities\n",
    "---\n",
    "\n",
    "The purpose of using Hybrid search is to optimize the RAG workflow in retrieving the right image description for specific questions. Some images (full or split in different parts), might not contain the information that is being asked by the question, because of the surrounding embeddings in the vector DB, so Hybrid search helps optimizing that. In this case, we will extract the entities of an image description (including the file name to be precise), then extract the entities of the question being asked, to get the most accurate response possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4d276-37ca-49b8-9787-020c31b8bb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity_extraction_prompt = \"\"\"\n",
    "Please provide a detailed description of the entities present in the image. Entities, are specific pieces of information or objects within a text that carry particular significance. These can be real-world entities like names of people, places, organizations, or dates. Refer to the types of entities: Named entities: These include names of people, organizations, locations, and dates. You can have specific identifiers within this, such as person names or person occupations.\n",
    "\n",
    "Custom entities: These are entities specific to a particular application or domain, such as product names, medical terms, or technical jargon.\n",
    "\n",
    "Temporal entities: These are entities related to time, such as dates, times, and durations.\n",
    "\n",
    "Product entities: Names of products might be grouped together into product entities.\n",
    "\n",
    "Data entities: Names of the data and metrics present. This includes names of metrics in charts, graphs and tables, and throughout the image.\n",
    "\n",
    "Now based on the image, create a list of these entities. Your response should be accurate. Do not make up an answer.\n",
    "\"\"\"\n",
    "\n",
    "logger.info(f\"prompt used to extract entities from the image: {entity_extraction_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b8685-58b6-42a2-b826-e243cac2b781",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1: Loop through b64 images to 1/get image desc from Claude3, 2/get embedding from Titan text. Call OSI pipeline API to ingest embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0326f1-5d73-48d0-90ce-db151918631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_txt_embeddings(bedrock: botocore.client, prompt_data: str) -> np.ndarray:\n",
    "    body = json.dumps({\n",
    "        \"inputText\": prompt_data,\n",
    "    })\n",
    "    try:\n",
    "        response = bedrock.invoke_model(\n",
    "            body=body, modelId=config['bedrock_model_info']['titan_model_id'], \n",
    "            accept=config['encoding_info']['accept_encoding'], contentType=config['encoding_info']['content_encoding']\n",
    "        )\n",
    "        response_body = json.loads(response['body'].read())\n",
    "        embedding = response_body.get('embedding')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"exception={e}\")\n",
    "        embedding = None\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f3fd2-303d-4a58-b707-5a6e8b731e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to get the image description and store the embeddings of that text in the image index\n",
    "def process_image_data(i: int, \n",
    "                       file_path: str, \n",
    "                       osi_endpoint, \n",
    "                       total: int) -> Dict:\n",
    "    bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=region, endpoint_url=endpoint_url)\n",
    "    json_data: Optional[Dict] = None\n",
    "    # name of the images that are saved (either split in 4 ways or saved as a single page)\n",
    "    image_name: Optional[str] = None\n",
    "    try:\n",
    "        image_file_extn: str = config['content_info']['image_extn']\n",
    "        bucket_img_prefix: str = os.path.join(config['pdf_dir_info']['bucket_prefix'], \n",
    "                                              config['pdf_dir_info']['bucket_img_prefix'])\n",
    "        logger.info(f\"going to convert {file_path} into embeddings\")\n",
    "        # first, get the entities from the image to prefilter the image description with the entities\n",
    "        entities_extracted = get_img_desc(file_path, entity_extraction_prompt)\n",
    "        # get the image description and prefilter the image description with the entities extracted from the image\n",
    "        content_description = entities_extracted + get_img_desc(file_path, prompt)\n",
    "        print(f\"file_path: {file_path}, image description (prefiltered with entities extracted): {content_description}\")\n",
    "        # embedding = get_text_embedding(bedrock, content_description)\n",
    "        embedding = get_img_txt_embeddings(bedrock, content_description)\n",
    "\n",
    "        if config['content_info']['content_type'] == 'slide_deck':\n",
    "            input_image_s3 = f\"s3://{bucket_name}/{bucket_img_prefix}/{Path(file_path).stem}{image_file_extn}\"\n",
    "            obj_name = f\"{Path(file_path).stem}{image_file_extn}\"\n",
    "        elif config['content_info']['content_type'] == 'pdf':\n",
    "            input_image_s3 = f\"s3://{bucket_name}/{bucket_img_prefix}/{Path(file_path).stem}{image_file_extn}\"\n",
    "            obj_name = f\"{Path(file_path).stem}{image_file_extn}\"\n",
    "\n",
    "        data = json.dumps([{\n",
    "            \"file_path\": input_image_s3,\n",
    "            \"file_text\": content_description,\n",
    "            \"page_number\": re.search(r\"page_(\\d+)_?\", obj_name).group(1),\n",
    "            \"metadata\": {\n",
    "                \"filename\": obj_name,\n",
    "                \"entities\": entities_extracted\n",
    "            },\n",
    "            \"vector_embedding\": embedding\n",
    "        }])\n",
    "        json_data = {\n",
    "            \"file_type\": config['content_info']['image_extn'],\n",
    "            \"file_name\": obj_name,\n",
    "            \"text\": content_description,\n",
    "            \"entities\": entities_extracted,\n",
    "            \"page_number\": re.search(r\"page_(\\d+)_?\", obj_name).group(1)\n",
    "            # \"page_number\": re.search(r\"_(\\d+)_?\", obj_name).group(1)\n",
    "            }\n",
    "        image_dir: str = config['pdf_dir_info']['json_img_dir']\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        fpath = os.path.join(image_dir, f\"{Path(file_path).stem}.json\")\n",
    "        print(f\"json_file_path: {fpath}\")\n",
    "        Path(fpath).write_text(json.dumps(json_data, default=str, indent=2))\n",
    "        r = requests.request(\n",
    "            method='POST', \n",
    "            url=osi_endpoint, \n",
    "            data=data,\n",
    "            auth=AWSSigV4('osis'))\n",
    "        logger.info(\"Ingesting data into pipeline\")\n",
    "        logger.info(f\"image desc: {r.text}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing image {file_path}: {e}\")\n",
    "        json_data: Optional[Dict] = None\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e4057-a30e-4b88-a1e7-6c55986f8b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def async_process_image_data(i: int, file_path: str, osi_endpoint, total: int):\n",
    "    logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return process_image_data(i, file_path, osi_endpoint, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937d157-f346-499f-8ef1-79686f2f28e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "erroneous_page_count: int = 0\n",
    "n: int = config['parallel_inference_count']\n",
    "image_chunks = [b64_image_file_list[i:i + n] for i in range(0, len(b64_image_file_list), n)]\n",
    "for chunk_index, image_chunk in enumerate(image_chunks):\n",
    "    try:\n",
    "        st = time.perf_counter()\n",
    "        logger.info(f\"------ getting text description for chunk {chunk_index}/{len(image_chunks)} -----\")\n",
    "        # Iterate over each file path in the chunk and process it individually\n",
    "        logger.info(f\"getting inference for list {chunk_index+1}/{len(image_chunks)}, size of list={len(image_chunk)} \")\n",
    "        results = ray.get([async_process_image_data.remote(index, file_path, osi_img_endpoint, len(image_chunk)) for index, file_path in enumerate(image_chunk)])\n",
    "        elapsed_time = time.perf_counter() - st\n",
    "        logger.info(f\"------ completed chunk={chunk_index}/{len(image_chunks)} completed in {elapsed_time} ------ \")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing chunk {chunk_index}: {e}\")\n",
    "        erroneous_page_count += len(image_chunk)\n",
    "\n",
    "logger.info(f\"Number of erroneous pdf pages that are not processed: {erroneous_page_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8fe93-1cde-4d0f-ae1d-6dd5b3f9040d",
   "metadata": {},
   "source": [
    "### Part 2: Loop through text files to 1/get text desc from Claude3, 2/get embedding from Titan text. Call OSI pipeline API to ingest embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68475cb8-0430-476d-8ae9-b22dad72aa26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of all files in the current directory\n",
    "pdf_txt_file_list = os.listdir(g.PDF_TEXT_DIR)\n",
    "\n",
    "# Get relative file paths by joining directory path with each file name\n",
    "pdf_txt_file_list = [os.path.join(g.PDF_TEXT_DIR, file) for file in pdf_txt_file_list]\n",
    "print(pdf_txt_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36dc23f-7a18-4ce3-9147-214b05eb56d2",
   "metadata": {},
   "source": [
    "#### Entities extraction from PDF texts using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b546f2-90ad-483c-8670-b47d084e147c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "def get_continuous_chunks(text):\n",
    "    \"\"\"\n",
    "    This function uses nltk to get the entities from texts that are extracted from pdf files\n",
    "    \"\"\"\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "    for i in chunked:\n",
    "        if type(i) == Tree:\n",
    "            current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "        if current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b18389-711e-44b3-b06e-f9b50685f63f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_text_data(txt_file: str, txt_page_index: int):\n",
    "    with open(txt_file, 'r') as file:\n",
    "        extracted_pdf_text = file.read()\n",
    "\n",
    "    # Extract entities from text\n",
    "    entities = get_continuous_chunks(extracted_pdf_text)\n",
    "    # Convert entities list to string\n",
    "    entities_str = \", \".join(entities)\n",
    "    logger.info(f\"entities extracted from {txt_file}: {entities_str}\")\n",
    "\n",
    "    # Your existing code for embeddings and JSON data\n",
    "    embedding = get_text_embedding(bedrock, extracted_pdf_text)\n",
    "    input_text_s3 = f\"s3://{bucket_name}/{g.BUCKET_PDF_TEXT_PREFIX}/{Path(txt_file).stem}{g.TEXT_FILE_EXTN}\"\n",
    "    obj_name = f\"{Path(txt_file).stem}{g.TEXT_FILE_EXTN}\"\n",
    "    data = json.dumps([{\n",
    "        \"file_path\": input_text_s3, \n",
    "        \"file_text\": extracted_pdf_text,\n",
    "        \"page_number\": txt_page_index, \n",
    "        \"metadata\": {\n",
    "            \"filename\": obj_name, \n",
    "            \"entities\": entities_str \n",
    "        },\n",
    "        \"vector_embedding\": embedding\n",
    "    }])\n",
    "    json_data = {\n",
    "        \"file_type\": g.TEXT_FILE_EXTN,\n",
    "        \"file_name\": Path(txt_file).stem,\n",
    "        \"text\": extracted_pdf_text, \n",
    "        \"page_number\": re.search(r\"text_(\\d+)_?\", obj_name).group(1),\n",
    "        \"entities\": entities_str  \n",
    "    }\n",
    "    os.makedirs(g.JSON_TEXT_DIR, exist_ok=True)\n",
    "    fpath = os.path.join(g.JSON_TEXT_DIR, f\"{Path(txt_file).stem}.json\")\n",
    "    print(f\"json_file_path: {fpath}\")\n",
    "    Path(fpath).write_text(json.dumps(json_data, default=str, indent=2))\n",
    "    r = requests.request(\n",
    "        method='POST',\n",
    "        url=osi_text_endpoint,\n",
    "        data=data,\n",
    "        auth=AWSSigV4('osis'))\n",
    "\n",
    "    logger.info(\"Ingesting data into pipeline\")\n",
    "    logger.info(f\"Response: {txt_page_index} - {r.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f47e1f-b730-4451-856a-931e3f7e5682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt_page_index: int = 1\n",
    "os.makedirs(g.JSON_TEXT_DIR, exist_ok=True)\n",
    "for txt_file in pdf_txt_file_list:\n",
    "    logger.info(f\"going to convert {txt_file} into embeddings\")\n",
    "    process_text_data(txt_file, txt_page_index)\n",
    "    txt_page_index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
