{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c37157-7d48-4422-a107-7c2ddd843747",
   "metadata": {},
   "source": [
    "## Step 1. Setup & Data Preparation for PDF files\n",
    "---\n",
    "\n",
    "This notebook does as follows:\n",
    "\n",
    "1. Install the required Python packages and import the relevant files.\n",
    "\n",
    "1. Utilize the PDF files available in the `pdf_data` directory that are specified in the `config.yaml` file under the `content_info` section.\n",
    "\n",
    "1. Extracts text from each page of the PDF file using the `PyPDF2` library and storing each in a `.txt` file. \n",
    "\n",
    "1. Converts each page in the PDF file into an image and crops it in 4 parts: 2 horizontal and 2 vertical halves and stores it as `.jpg` files based on how many parts a user wants to split the image into\n",
    "\n",
    "1. Stores the extracted texts and images in an S3 bucket for further analytics and RAG workflow purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605ceea-e65d-4822-bbf5-d96f0ae77a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install the requirements\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e2d0f4-7495-4f54-a5b7-3a20a4524516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libaries required to run this notebook\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import fitz\n",
    "import glob\n",
    "import boto3\n",
    "import PyPDF2\n",
    "import base64\n",
    "import logging\n",
    "import sagemaker\n",
    "import globals as g\n",
    "from PIL import Image\n",
    "import requests as req\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import pypdfium2 as pdfium\n",
    "from typing import Dict, Optional\n",
    "from utils import upload_to_s3, get_bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836b91e-18a9-4d4b-83ac-df3a5bb80389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set a logger\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c4278-c6ae-46b3-b174-0cda43f6198f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "CONFIG_FILE_PATH = \"config.yaml\"\n",
    "\n",
    "# read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5726f-55a7-4188-afa5-b4623c199ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name: str = get_bucket_name(config['aws']['cfn_stack_name'])\n",
    "logger.info(f\"Bucket name being used to store extracted images and texts from data: {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e9cb3-fdcd-463d-a803-c71f88a7d207",
   "metadata": {},
   "source": [
    "## Step 2. Download PDF files from a local directory/extract it from a `public url` and store the text and images for each page in a pdf folder\n",
    "\n",
    "For the purpose of this POC we will manually use sample PDF files within the `pdf_data` folder. To use your own pdf files, insert the pdf files in the `pdf_data` folder, or mention the `http url` to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3351b-b87c-4a77-b222-6be9b0f295ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ImageCrop(fname: str, left_outfile: str, right_outfile: str, upper_outfile: str, lower_outfile: str):\n",
    "    \"\"\"\n",
    "    This function crops a given image (using the image file path) into two vertical halves\n",
    "    , two horizontal halves and saves them as separate images in the the associated image paths\n",
    "    \"\"\"\n",
    "    img = Image.open(fname)\n",
    "    width, height = img.size\n",
    "    # Coordinates for the left half\n",
    "    left_half = img.crop((0, 0, width / 2, height))\n",
    "    left_half.save(left_outfile, 'JPEG')\n",
    "    # Coordinates for the right half\n",
    "    right_half = img.crop((width / 2, 0, width, height))\n",
    "    right_half.save(right_outfile, 'JPEG')\n",
    "    # Coordinates for the upper half\n",
    "    upper_half = img.crop((0, 0, width, height / 2))\n",
    "    upper_half.save(upper_outfile, 'JPEG')\n",
    "    # Coordinates for the lower half\n",
    "    lower_half = img.crop((0, height / 2, width, height))\n",
    "    lower_half.save(lower_outfile, 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab8550-fd97-453c-9f7d-be321b489d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(file:str, image_dir:str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get PIL images from PDF pages and save them to a specified directory\n",
    "    :param file: Path to file\n",
    "    :return: A list of PIL images\n",
    "    \"\"\"\n",
    "    pdf = pdfium.PdfDocument(file)\n",
    "    # the image scale is configured in the config.yaml file \n",
    "    image_scale: float = config['page_split_imgs']['image_scale']\n",
    "    n_pages: int = len(pdf)\n",
    "    file_name: str = Path(file).stem  \n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    image_paths: List[str] = []\n",
    "    print(f\"Extracting {n_pages} images for {file}\")\n",
    "    for page_number in range(n_pages):\n",
    "        page = pdf.get_page(page_number)\n",
    "        bitmap = page.render(scale=image_scale, rotation=0, crop=(0, 0, 0, 0))\n",
    "        pil_image = bitmap.to_pil()\n",
    "        # Saving the image with the specified naming convention\n",
    "        image_path = os.path.join(image_dir, f\"{file_name}_page_{page_number + 1}.jpg\")\n",
    "        pil_image.save(image_path, format=config['pdf_dir_info']['image_format'])\n",
    "        # append the image path and return the path to where the image is saved\n",
    "        image_paths.append(image_path)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370e879-b484-42cd-a513-eaf1f2d4b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if you have manually uploaded the images from the pdf page in a `manually_saved_images_path` directory, those are used in this notebook instead\n",
    "manual_img_path: str = os.path.join(config['pdf_dir_info']['manually_saved_images_path'], \"*\", \"*.jpg\")\n",
    "manually_uploaded_img_files = glob.glob(manual_img_path, recursive=True)\n",
    "logger.info(f\"there are {len(manually_uploaded_img_files)} files in {manual_img_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a51aa3-5ca3-4cd6-a238-0b43036b77a4",
   "metadata": {},
   "source": [
    "### Step 3: Extract the `text files` and `images` from each `page in the PDF file` and store it in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6b908-15f3-4076-aa52-b8052892bc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_texts_and_images(pdf_file: str, output_dir: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Get images and texts from each page of a given pdf file and store it in\n",
    "    each page directory, containing a text_dir for texts extracted from pdf images, and image_dir\n",
    "    to store images extracted for that pdf page\n",
    "    return: Dictionary containing the page number, and paths to the texts and image files \n",
    "            generated from each pdf page\n",
    "    \"\"\"\n",
    "    # Dict containing the text and image paths, along with the page number\n",
    "    path_info: Dict = {\n",
    "        'page_number': [],\n",
    "        'image_paths': [],\n",
    "        'text_paths': []\n",
    "    }\n",
    "    # Open the PDF file. Insert your pdf files in this directory to use custom pdf files\n",
    "    pdf_fpath: str = os.path.join(config['pdf_dir_info']['source_pdf_dir'], pdf_file)\n",
    "    logger.info(f\"Reading PDF file: {pdf_fpath}\")\n",
    "    # Use 'PdfReader' for extracting texts, images and other data from PDF documents\n",
    "    pdf_reader = PyPDF2.PdfReader(open(pdf_fpath, \"rb\"))\n",
    "    pdf_document = fitz.open(pdf_fpath)\n",
    "    num_pages: int = len(pdf_reader.pages)\n",
    "    # Extracting file name and creating the directory for each page of the pdf\n",
    "    file_name: str = Path(pdf_file).stem\n",
    "    output_pdf_dir = os.path.join(output_dir, file_name)\n",
    "    # directories where the texts and images extracted from each page of a pdf file are saved\n",
    "    text_dir = os.path.join(output_pdf_dir, config['pdf_dir_info']['pdf_txt_path'])\n",
    "    image_dir = os.path.join(output_pdf_dir, config['pdf_dir_info']['pdf_img_path'])\n",
    "    os.makedirs(text_dir, exist_ok=True)\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    # Extract pages as images from the PDF file\n",
    "    image_paths = get_images(pdf_fpath, image_dir)\n",
    "    # Iterate over the pages and extract the text and images from each page\n",
    "    for page_number in range(num_pages):\n",
    "        # Get the page object\n",
    "        page = pdf_reader.pages[page_number]\n",
    "        # Extract the text from the page\n",
    "        pdf_text = page.extract_text()\n",
    "        text_path = os.path.join(text_dir, f\"{file_name}_text_{page_number + 1}{config['content_info']['text_extn']}\")\n",
    "        with open(text_path, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(pdf_text)\n",
    "        # if the images are manually not provided, do the split&save of images as the user configured in the \n",
    "        # config file for each page of the pdf file\n",
    "        if config['manually_saved_images_provided'] is False:\n",
    "            # Append the entire page image path to the list of image paths\n",
    "            page_image = os.path.join(image_dir, f\"{file_name}_page_{page_number + 1}.jpg\")\n",
    "            image_paths.append(page_image)\n",
    "            # Split it in half vertically\n",
    "            left_half_path = os.path.join(image_dir, f\"{file_name}_page_{page_number + 1}_left_half{g.IMAGE_FILE_EXTN}\")\n",
    "            right_half_path = os.path.join(image_dir, f\"{file_name}_page_{page_number + 1}_right_half{g.IMAGE_FILE_EXTN}\")\n",
    "            # Split it in half horizontally\n",
    "            upper_half_path = os.path.join(image_dir, f\"{file_name}_page_{page_number + 1}_upper_half{g.IMAGE_FILE_EXTN}\")\n",
    "            lower_half_path = os.path.join(image_dir, f\"{file_name}_page_{page_number + 1}_lower_half{g.IMAGE_FILE_EXTN}\")\n",
    "            # Crop and save the image halves. Now we we have image paths saved for each crop\n",
    "            ImageCrop(image_paths[page_number], left_half_path, right_half_path, upper_half_path, lower_half_path)\n",
    "            # if the user wants the image to be split all 4 ways, then save all four different files\n",
    "            if config['page_split_imgs']['horizontal_split'] and config['page_split_imgs']['vertical_split'] is True:\n",
    "                path_info['image_paths'].extend([left_half_path, right_half_path, upper_half_path, lower_half_path,  page_image])\n",
    "            # if the user wants the image to only be split vertically, only save the left and right side of the image\n",
    "            elif config['page_split_imgs']['horizontal_split'] is False and config['page_split_imgs']['vertical_split'] is True:\n",
    "                path_info['image_paths'].extend([left_half_path, right_half_path, page_image])\n",
    "            # if the user wants the image to only be split horizontally, only save the upper and lower side of the image\n",
    "            elif config['page_split_imgs']['horizontal_split'] is True and config['page_split_imgs']['vertical_split'] is False:\n",
    "                path_info['image_paths'].extend([upper_half_path, lower_half_path, page_image])\n",
    "            # if none are set to 'yes', then append the image path to the page as a single image without cropping\n",
    "            else:\n",
    "                path_info['image_paths'].extend([page_image])\n",
    "        else:\n",
    "            # if the user has provided a path to an image that is uploaded manually in a dir, then use that instead\n",
    "            path_info['image_paths'].extend(manually_uploaded_img_files)\n",
    "        # save the text and page number of the given page from the pdf file\n",
    "        path_info['text_paths'].append(text_path)\n",
    "        path_info['page_number'].append(page_number)\n",
    "    return path_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07790dc2-21f4-461e-a4cc-1127ca9dffd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Are the images manually given as screenshots from files: {config['manually_saved_images_provided']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814fa33-b236-4962-bf4a-426ce626d8cf",
   "metadata": {},
   "source": [
    "#### Download a publicly available pdf file or your custom file from the `pdf_data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db6240-c5a6-48d6-a0d5-6056004b0bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_list: str = config['content_info']['pdf_local_files']\n",
    "logger.info(f\"List of pdf content provided: {content_list}\")\n",
    "local_files: List[str] = []\n",
    "for pdf_file in content_list:\n",
    "    if 'https://' in pdf_file or 'http://' in pdf_file:\n",
    "        local_file: str = os.path.basename(url)\n",
    "        r = req.get(url, allow_redirects=True)\n",
    "        if r.status_code == 200:\n",
    "            logger.info(f\"{url} downloaded successfully\")\n",
    "            with open(local_file, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            logger.info(f\"{url} written to {local_file}\")\n",
    "    else:\n",
    "        local_file = pdf_file\n",
    "        local_files.append(local_file)\n",
    "    logger.info(f\"saved pdf file: {pdf_file}\")\n",
    "logger.info(f\"total files saved: {len(local_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cebebe-a117-42f9-b604-7b3011974551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract the separate text and images files into a 'pages_stored' list\n",
    "pages_stored: List[str] = []\n",
    "for local_file in local_files:\n",
    "    pages = extract_texts_and_images(local_file, config['pdf_dir_info']['pdf_extracted_data'])\n",
    "    pages_stored.append(pages)\n",
    "logger.info(f\"Images and Page texts have been extracted from {len(local_files)} PDF file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bf1af-ca75-4d1f-b91f-a1cdd506683a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view all pages stored (including text and images) that need to be uploaded to S3 for further use\n",
    "# Displays the page numbers, associated image paths that will be uploaded to S3, and the text files\n",
    "# for each pdf page that will be uploaded to S3\n",
    "pages_stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53600f15-e57b-4e0a-97ab-5f96c93386a3",
   "metadata": {},
   "source": [
    "Now we upload the images into an S3 bucket. This is done for two reasons:\n",
    "1. In a production environment these images could be worked upon in parallel by a batch process.\n",
    "1. An S3 bucket (that is part of a datalake) provides a secure location for an enterprise to store these images and a multimodal model can read the texts/images directly from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa5e75-7c5f-4128-8d6b-df788fb69c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the text and image files from each pdf page from each pdf file in an s3 bucket path\n",
    "for pdf_stored in pages_stored:\n",
    "    _ = list(map(lambda img_path: upload_to_s3(img_path, bucket_name, g.BUCKET_IMG_PREFIX), pdf_stored['image_paths']))\n",
    "    _ = list(map(lambda txt_path: upload_to_s3(txt_path, bucket_name, g.BUCKET_PDF_TEXT_PREFIX), pdf_stored['text_paths']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
