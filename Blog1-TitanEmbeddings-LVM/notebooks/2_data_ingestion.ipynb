{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbb582e-d21a-41cf-b45e-e2f462424ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data ingestion\n",
    "\n",
    "***This notebook works best with the `conda_python3` on the `ml.t3.large` instance***.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we download the images corresponding to the slide deck that we uploaded into Amazon S3 in the [1_data_prep.ipynb](./1_data_prep) notebook, convert them into embeddings and then ingest these embeddings into a vector database i.e. [Amazon OpenSearch Service Serverless](https://aws.amazon.com/opensearch-service/features/serverless/).\n",
    "\n",
    "1. We use the [Amazon Titan Multiodal Embeddings](https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-titan-multimodal-embeddings-model-bedrock/) model to convert the images into embeddings.\n",
    "\n",
    "1. The embeddings are then ingested into OpenSearch Service Serverless using the [Amazon OpenSearch Ingestion](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/ingestion.html) pipeline. The embeddings are uploaded into an S3 bucket and that triggers the OpenSearch Ingestion pipeline which ingests the data into an OpenSearch Serverless index.\n",
    "\n",
    "1. The OpenSearch Service Serverless Collection is created via the AWS CloudFormation stack for this blog post.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a62857-6a66-44db-9d92-3df221c6bd21",
   "metadata": {},
   "source": [
    "## Step 1. Setup\n",
    "\n",
    "Install the required Python packages and import the relevant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7f869e5d-8e4b-4d44-9e2a-4f20b77b92d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub==0.19.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.19.4)\n",
      "Requirement already satisfied: sagemaker==2.199.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.199.0)\n",
      "Requirement already satisfied: pypdfium2==4.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.24.0)\n",
      "Requirement already satisfied: httplib2==0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.19.0)\n",
      "Requirement already satisfied: langchain==0.0.340 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.0.340)\n",
      "Requirement already satisfied: requests==2.31.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: pandas==1.5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: boto3==1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.34.0)\n",
      "Requirement already satisfied: botocore==1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.34.0)\n",
      "Requirement already satisfied: opensearch-py==2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.4.2)\n",
      "Requirement already satisfied: numexpr==2.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.8.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (23.2)\n",
      "Requirement already satisfied: docutils in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.16)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (4.25.2)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (6.8.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.7.5)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (4.19.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (3.11.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: urllib3<1.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (1.26.18)\n",
      "Requirement already satisfied: uvicorn==0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.22.0)\n",
      "Requirement already satisfied: fastapi==0.95.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.95.2)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (6.1.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httplib2==0.19.0->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (0.0.83)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (1.10.13)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (8.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0->-r requirements.txt (line 6)) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0->-r requirements.txt (line 6)) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 7)) (2023.3.post1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.34.0->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.34.0->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py==2.4.2->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fastapi==0.95.2->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.27.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn==0.22.0->sagemaker==2.199.0->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn==0.22.0->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340->-r requirements.txt (line 5)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340->-r requirements.txt (line 5)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.340->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.340->-r requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340->-r requirements.txt (line 5)) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.199.0->-r requirements.txt (line 2)) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.340->-r requirements.txt (line 5)) (2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.340->-r requirements.txt (line 5)) (3.0.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from docker->sagemaker==2.199.0->-r requirements.txt (line 2)) (1.6.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker==2.199.0->-r requirements.txt (line 2)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.10.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker==2.199.0->-r requirements.txt (line 2)) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from schema->sagemaker==2.199.0->-r requirements.txt (line 2)) (21.6.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340->-r requirements.txt (line 5)) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "beda5d30-06f7-44a6-9b1d-8ac27fb93cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import codecs\n",
    "import base64\n",
    "import logging\n",
    "import botocore\n",
    "import numpy as np\n",
    "import globals as g\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from utils import upload_to_s3, get_cfn_outputs, get_bucket_name, download_image_files_from_s3\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bcf9ddf2-d8f5-404a-8fcf-a5efa3f3fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name: str = get_bucket_name(g.CFN_STACK_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e4e12-1803-419d-ba38-af9d88b025d8",
   "metadata": {},
   "source": [
    "## Step 2. Download the images files from S3 and convert to Base64 \n",
    "\n",
    "Now we download the image files from the S3 bucket. Once downloaded these files are converted into [Base64](https://en.wikipedia.org/wiki/Base64) encoding so that we can create embeddings from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "130ccdb0-8e2e-47bc-bd90-34ff8cba1964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-23 17:07:35,444] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_1.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_1.jpg\n",
      "[2024-01-23 17:07:35,503] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_10.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_10.jpg\n",
      "[2024-01-23 17:07:35,545] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_11.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_11.jpg\n",
      "[2024-01-23 17:07:35,591] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_12.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_12.jpg\n",
      "[2024-01-23 17:07:35,641] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_13.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_13.jpg\n",
      "[2024-01-23 17:07:35,687] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_14.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_14.jpg\n",
      "[2024-01-23 17:07:35,736] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_15.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_15.jpg\n",
      "[2024-01-23 17:07:35,788] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_16.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_16.jpg\n",
      "[2024-01-23 17:07:35,819] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_17.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_17.jpg\n",
      "[2024-01-23 17:07:35,914] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_18.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_18.jpg\n",
      "[2024-01-23 17:07:35,953] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_19.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_19.jpg\n",
      "[2024-01-23 17:07:36,006] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_2.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_2.jpg\n",
      "[2024-01-23 17:07:36,046] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_20.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_20.jpg\n",
      "[2024-01-23 17:07:36,117] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_21.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_21.jpg\n",
      "[2024-01-23 17:07:36,147] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_22.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_22.jpg\n",
      "[2024-01-23 17:07:36,191] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_23.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_23.jpg\n",
      "[2024-01-23 17:07:36,217] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_24.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_24.jpg\n",
      "[2024-01-23 17:07:36,304] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_25.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_25.jpg\n",
      "[2024-01-23 17:07:36,355] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_26.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_26.jpg\n",
      "[2024-01-23 17:07:36,412] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_27.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_27.jpg\n",
      "[2024-01-23 17:07:36,457] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_28.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_28.jpg\n",
      "[2024-01-23 17:07:36,509] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_29.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_29.jpg\n",
      "[2024-01-23 17:07:36,568] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_3.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_3.jpg\n",
      "[2024-01-23 17:07:36,595] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_30.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_30.jpg\n",
      "[2024-01-23 17:07:36,687] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_31.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_31.jpg\n",
      "[2024-01-23 17:07:36,716] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_4.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_4.jpg\n",
      "[2024-01-23 17:07:36,815] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_5.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_5.jpg\n",
      "[2024-01-23 17:07:36,856] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_6.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_6.jpg\n",
      "[2024-01-23 17:07:36,909] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_7.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_7.jpg\n",
      "[2024-01-23 17:07:36,935] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_8.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_8.jpg\n",
      "[2024-01-23 17:07:36,980] p29980 {utils.py:33} INFO - downloaded multimodal-bucket-597703351594/multimodal/img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_9.jpg to img/CMP301_TrainDeploy_E1_20230607_SPEdited_image_9.jpg\n",
      "[2024-01-23 17:07:36,981] p29980 {1297213205.py:3} INFO - downloaded 31 from s3\n"
     ]
    }
   ],
   "source": [
    "# download images from S3, we would be converting these to embeddings\n",
    "image_files: List = download_image_files_from_s3(bucket_name, g.BUCKET_IMG_PREFIX, g.IMAGE_DIR, g.IMAGE_FILE_EXTN)\n",
    "logger.info(f\"downloaded {len(image_files)} from s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bbfe98-f792-447c-9878-018b2d3ea3c6",
   "metadata": {},
   "source": [
    "Convert jpg files into Base64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea7ee6d6-0d23-4481-ac3e-d72a2219bc65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_file_path: str) -> str:\n",
    "    with open(image_file_path, \"rb\") as image_file:\n",
    "        b64_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "        b64_image_path = os.path.join(g.B64_ENCODED_IMAGES_DIR, f\"{Path(image_file_path).stem}.b64\")\n",
    "        with open(b64_image_path, \"wb\") as b64_image_file:\n",
    "            b64_image_file.write(bytes(b64_image, 'utf-8'))\n",
    "    return b64_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d4478ad-9673-4ab5-993e-f0437b3926ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-23 17:07:36,999] p29980 {4025043965.py:3} INFO - there are 31 files in the img directory for conversion to base64\n",
      "[2024-01-23 17:07:37,008] p29980 {4025043965.py:7} INFO - base64 conversion done, there are 31 base64 encoded files\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(g.B64_ENCODED_IMAGES_DIR, exist_ok=True)\n",
    "file_list: List = glob.glob(os.path.join(g.IMAGE_DIR, f\"*{g.IMAGE_FILE_EXTN}\"))\n",
    "logger.info(f\"there are {len(file_list)} files in the {g.IMAGE_DIR} directory for conversion to base64\")\n",
    "\n",
    "# convert each file to base64 and store the base64 in a new file\n",
    "b64_image_file_list = list(map(encode_image_to_base64, file_list))\n",
    "logger.info(f\"base64 conversion done, there are {len(b64_image_file_list)} base64 encoded files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a2add-dfda-430a-b93a-c3bf44c8c85b",
   "metadata": {},
   "source": [
    "## Step 3. Get embeddings for the base64 encoded images\n",
    "\n",
    "Now we are ready to use Amazon Bedrock via the Amazon Titan Multimodal Embeddings model to convert the base64 version of the images into embeddings. We store these embeddings into a single JSON file which is then uploaded into S3. \n",
    "\n",
    "It is important to note that the embeddings corresponding to all the images are stored in a single file so that they can be ingested into the vector database in a single PUT operation (one bulk ingest call is more effecient than one ingest call for each image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8b38cd73-0bce-4313-bc2b-d9cc33a3bb79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_multimodal_embeddings(bedrock: botocore.client, image: str) -> np.ndarray:\n",
    "    body = json.dumps(dict(inputImage=image))\n",
    "    try:\n",
    "        response = bedrock.invoke_model(\n",
    "            body=body, modelId=g.FMC_MODEL_ID, accept=g.ACCEPT_ENCODING, contentType=g.CONTENT_ENCODING\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        embeddings = np.array([response_body.get(\"embedding\")]).astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"exception while image(truncated)={image[:10]}, exception={e}\")\n",
    "        embeddings = None\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "106a99c9-2aae-4062-9c22-90e2609910a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-23 17:07:37,034] p29980 {2086549339.py:4} INFO - there are 31 to convert to embeddings\n",
      "[2024-01-23 17:07:37,036] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_2.b64 into embeddings\n",
      "[2024-01-23 17:07:37,185] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_2.b64 to embeddings in 0.15 seconds\n",
      "[2024-01-23 17:07:37,186] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_2.b64\n",
      "[2024-01-23 17:07:37,186] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_27.b64 into embeddings\n",
      "[2024-01-23 17:07:37,347] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_27.b64 to embeddings in 0.16 seconds\n",
      "[2024-01-23 17:07:37,348] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_27.b64\n",
      "[2024-01-23 17:07:37,348] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_22.b64 into embeddings\n",
      "[2024-01-23 17:07:37,473] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_22.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:37,475] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_22.b64\n",
      "[2024-01-23 17:07:37,476] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_24.b64 into embeddings\n",
      "[2024-01-23 17:07:37,597] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_24.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:37,598] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_24.b64\n",
      "[2024-01-23 17:07:37,599] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_8.b64 into embeddings\n",
      "[2024-01-23 17:07:37,720] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_8.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:37,722] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_8.b64\n",
      "[2024-01-23 17:07:37,722] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_15.b64 into embeddings\n",
      "[2024-01-23 17:07:37,844] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_15.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:37,845] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_15.b64\n",
      "[2024-01-23 17:07:37,846] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_26.b64 into embeddings\n",
      "[2024-01-23 17:07:37,978] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_26.b64 to embeddings in 0.13 seconds\n",
      "[2024-01-23 17:07:37,980] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_26.b64\n",
      "[2024-01-23 17:07:37,981] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_12.b64 into embeddings\n",
      "[2024-01-23 17:07:38,117] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_12.b64 to embeddings in 0.13 seconds\n",
      "[2024-01-23 17:07:38,118] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_12.b64\n",
      "[2024-01-23 17:07:38,118] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_25.b64 into embeddings\n",
      "[2024-01-23 17:07:38,236] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_25.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:38,236] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_25.b64\n",
      "[2024-01-23 17:07:38,237] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_23.b64 into embeddings\n",
      "[2024-01-23 17:07:38,353] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_23.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:38,354] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_23.b64\n",
      "[2024-01-23 17:07:38,355] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_6.b64 into embeddings\n",
      "[2024-01-23 17:07:38,485] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_6.b64 to embeddings in 0.13 seconds\n",
      "[2024-01-23 17:07:38,486] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_6.b64\n",
      "[2024-01-23 17:07:38,487] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_29.b64 into embeddings\n",
      "[2024-01-23 17:07:38,610] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_29.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:38,611] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_29.b64\n",
      "[2024-01-23 17:07:38,611] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_30.b64 into embeddings\n",
      "[2024-01-23 17:07:38,737] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_30.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:38,738] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_30.b64\n",
      "[2024-01-23 17:07:38,739] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_31.b64 into embeddings\n",
      "[2024-01-23 17:07:38,852] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_31.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:38,853] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_31.b64\n",
      "[2024-01-23 17:07:38,854] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_9.b64 into embeddings\n",
      "[2024-01-23 17:07:38,968] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_9.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:38,969] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_9.b64\n",
      "[2024-01-23 17:07:38,970] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_13.b64 into embeddings\n",
      "[2024-01-23 17:07:39,082] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_13.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:39,083] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_13.b64\n",
      "[2024-01-23 17:07:39,084] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_20.b64 into embeddings\n",
      "[2024-01-23 17:07:39,210] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_20.b64 to embeddings in 0.13 seconds\n",
      "[2024-01-23 17:07:39,211] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_20.b64\n",
      "[2024-01-23 17:07:39,212] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_1.b64 into embeddings\n",
      "[2024-01-23 17:07:39,321] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_1.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:39,322] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_1.b64\n",
      "[2024-01-23 17:07:39,323] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_10.b64 into embeddings\n",
      "[2024-01-23 17:07:39,474] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_10.b64 to embeddings in 0.15 seconds\n",
      "[2024-01-23 17:07:39,475] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_10.b64\n",
      "[2024-01-23 17:07:39,476] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_4.b64 into embeddings\n",
      "[2024-01-23 17:07:39,584] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_4.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:39,584] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_4.b64\n",
      "[2024-01-23 17:07:39,586] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_11.b64 into embeddings\n",
      "[2024-01-23 17:07:39,699] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_11.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:39,700] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_11.b64\n",
      "[2024-01-23 17:07:39,700] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_5.b64 into embeddings\n",
      "[2024-01-23 17:07:39,830] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_5.b64 to embeddings in 0.13 seconds\n",
      "[2024-01-23 17:07:39,830] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_5.b64\n",
      "[2024-01-23 17:07:39,831] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_21.b64 into embeddings\n",
      "[2024-01-23 17:07:39,947] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_21.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:39,948] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_21.b64\n",
      "[2024-01-23 17:07:39,948] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_3.b64 into embeddings\n",
      "[2024-01-23 17:07:40,059] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_3.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:40,060] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_3.b64\n",
      "[2024-01-23 17:07:40,061] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_19.b64 into embeddings\n",
      "[2024-01-23 17:07:40,171] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_19.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:40,172] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_19.b64\n",
      "[2024-01-23 17:07:40,175] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_28.b64 into embeddings\n",
      "[2024-01-23 17:07:40,281] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_28.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:40,282] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_28.b64\n",
      "[2024-01-23 17:07:40,283] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_16.b64 into embeddings\n",
      "[2024-01-23 17:07:40,455] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_16.b64 to embeddings in 0.17 seconds\n",
      "[2024-01-23 17:07:40,462] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_16.b64\n",
      "[2024-01-23 17:07:40,463] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_17.b64 into embeddings\n",
      "[2024-01-23 17:07:40,579] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_17.b64 to embeddings in 0.11 seconds\n",
      "[2024-01-23 17:07:40,580] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_17.b64\n",
      "[2024-01-23 17:07:40,581] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_14.b64 into embeddings\n",
      "[2024-01-23 17:07:40,703] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_14.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:40,710] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_14.b64\n",
      "[2024-01-23 17:07:40,711] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_7.b64 into embeddings\n",
      "[2024-01-23 17:07:40,829] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_7.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:40,831] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_7.b64\n",
      "[2024-01-23 17:07:40,831] p29980 {2086549339.py:6} INFO - going to convert img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_18.b64 into embeddings\n",
      "[2024-01-23 17:07:40,953] p29980 {2086549339.py:20} INFO - successfully converted img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_18.b64 to embeddings in 0.12 seconds\n",
      "[2024-01-23 17:07:40,953] p29980 {2086549339.py:35} INFO - appended json data corresponding to img/b64_images/CMP301_TrainDeploy_E1_20230607_SPEdited_image_18.b64\n"
     ]
    }
   ],
   "source": [
    "embeddings_list = []\n",
    "bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=g.AWS_REGION, endpoint_url=g.FMC_URL)\n",
    "file_list: List = glob.glob(os.path.join(g.B64_ENCODED_IMAGES_DIR, \"*.b64\"))\n",
    "logger.info(f\"there are {len(file_list)} to convert to embeddings\")\n",
    "for image_file_path in file_list:\n",
    "    logger.info(f\"going to convert {image_file_path} into embeddings\")\n",
    "    \n",
    "    # read the file, MAX image size supported is 2048 * 2048 pixels\n",
    "    with open(image_file_path, \"rb\") as image_file:\n",
    "        input_image_b64 = image_file.read().decode('utf-8')\n",
    "    \n",
    "    # make a call to Bedrock to get the embeddings corresponding to\n",
    "    # this image's base64 data\n",
    "    st = time.perf_counter()\n",
    "    embeddings = get_multimodal_embeddings(bedrock, input_image_b64)\n",
    "    if embeddings is None:\n",
    "        logger.error(f\"error creating multimodal embeddings for {os.path.basename(image_file_path)}\")\n",
    "        continue\n",
    "    latency = time.perf_counter() - st\n",
    "    logger.info(f\"successfully converted {image_file_path} to embeddings in {latency:.2f} seconds\")\n",
    "    \n",
    "    # convert the data we want to ingest for this image into a JSON, this include the metadata as well\n",
    "    # the metadata can be used later as part of hybrid search from the vector db\n",
    "    data = {\n",
    "        \"image_path\": f\"s3://{bucket_name}/{g.BUCKET_IMG_PREFIX}/{Path(image_file_path).stem}{g.IMAGE_FILE_EXTN}\",\n",
    "        \"metadata\": {\n",
    "          \"slide_filename\": g.SLIDE_DECK,\n",
    "          \"model_id\": g.FMC_MODEL_ID,\n",
    "          \"slide_description\": \"\"\n",
    "        },\n",
    "        \"vector_embedding\": embeddings[0].tolist()\n",
    "      }\n",
    "    \n",
    "    embeddings_list.append(data)\n",
    "    logger.info(f\"appended json data corresponding to {image_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dbf1b54b-7306-436d-8c12-21e0a92fc3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-23 17:07:41,035] p29980 {1527796339.py:6} INFO - saved multimodal embeddings for all images in CMP301_TrainDeploy_E1_20230607_SPEdited.json\n"
     ]
    }
   ],
   "source": [
    "fpath: str = f\"{Path(g.SLIDE_DECK).stem}.json\"\n",
    "json.dump(embeddings_list, codecs.open(fpath, 'w', encoding='utf-8'), \n",
    "          separators=(',', ':'), \n",
    "          sort_keys=True, \n",
    "          indent=4)\n",
    "logger.info(f\"saved multimodal embeddings for all images in {fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b57d2df-d685-43da-a1b4-4212ec4772b2",
   "metadata": {},
   "source": [
    "## Step 4. Create the OpenSearch Service Serverless index\n",
    "\n",
    "**This step is only required until we get support creating an OpenSearch Service Serverless index via AWS CloudFormation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0acd94-ad70-4d98-95ca-fb7ea5eaa05b",
   "metadata": {},
   "source": [
    "Get the name of the OpenSearch Service Serverless collection endpoint and index name from the CloudFormation stack outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1e8ed38-2512-428f-a53c-b666466d2e70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-23 17:07:41,131] p29980 {2210621458.py:4} INFO - opensearchhost=nz2313ydxnjveocqyhvh.us-west-2.aoss.amazonaws.com, index=slides\n"
     ]
    }
   ],
   "source": [
    "outputs = get_cfn_outputs(g.CFN_STACK_NAME)\n",
    "host = outputs['MultimodalCollectionEndpoint'].split('//')[1]\n",
    "index_name = outputs['OpenSearchIndexName']\n",
    "logger.info(f\"opensearchhost={host}, index={index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953454d9-d335-4a2a-bbcb-852ea95a1de0",
   "metadata": {},
   "source": [
    "We use the OpenSearch client to create an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e5b2b2e-3c41-4ccd-8260-eb7caf247d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-23 17:07:41,165] p29980 {credentials.py:1075} INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, g.AWS_REGION, g.OS_SERVICE)\n",
    "\n",
    "os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56121d-441e-4d08-8375-78380ae380e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "The structure of the index is important. Note the following about the index.\n",
    "\n",
    "1. The index is a (k-NN](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/knn.html) index so that we can do a vector similarity search in this index.\n",
    "\n",
    "1. The vector dimension is 1024 which corresponds to the output dimension of the Amazon Titan Multimodal Embeddings model that we are using.\n",
    "\n",
    "1. The index uses the [`Hierarchical Navigable Small World (HNSW)`](https://aws.amazon.com/blogs/big-data/choose-the-k-nn-algorithm-for-your-billion-scale-use-case-with-opensearch/) algorithm for similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "06d77228-8db8-4302-a3f9-77cba53a7061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-23 17:07:41,501] p29980 {base.py:281} WARNING - PUT https://nz2313ydxnjveocqyhvh.us-west-2.aoss.amazonaws.com:443/slides [status:400 request:0.327s]\n",
      "[2024-01-23 17:07:41,502] p29980 {3838889910.py:45} ERROR - error in creating index=slides, exception=RequestError(400, 'resource_already_exists_exception', 'OpenSearch exception [type=resource_already_exists_exception, reason=index [slides/lQZKN40BmLq5qD0rvGuO] already exists]- server : [envoy]')\n"
     ]
    }
   ],
   "source": [
    "index_body = \"\"\"\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index.knn\": true\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"vector_embedding\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 1024,\n",
    "        \"method\": {\n",
    "          \"name\": \"hnsw\",\n",
    "          \"engine\": \"nmslib\",\n",
    "          \"parameters\": {}\n",
    "        }\n",
    "      },\n",
    "      \"image_path\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "       \"metadata\": { \n",
    "        \"properties\" :\n",
    "          {\n",
    "            \"slide_filename\" : {\n",
    "              \"type\" : \"text\"\n",
    "            },\n",
    "            \"model_id\" : {\n",
    "              \"type\" : \"text\"\n",
    "            },\n",
    "            \"slide_description\":{\n",
    "              \"type\": \"text\"\n",
    "            }\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# We would get an index already exists exception if the index already exists, and that is fine.\n",
    "index_body = json.loads(index_body)\n",
    "try:\n",
    "    response = os_client.indices.create(index_name, body=index_body)\n",
    "    logger.info(f\"response received for the create index -> {response}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"error in creating index={index_name}, exception={e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b27818a-8b7c-4cad-8657-cec343f8c815",
   "metadata": {},
   "source": [
    "## Step 5. Upload the embeddings file to S3\n",
    "\n",
    "Now we are all set for ingesting the embeddings file that contains multimodal embeddings for all the slides in our slide deck into OpenSearch Service Serverless.\n",
    "\n",
    "We do this by simply uploading the file in the designated S3 bucket (see CloudFormation template [`template.yaml`](../template.yaml)) and that triggers a run of the OpenSearch Ingestion pipeline which ultimately ingests the data into the OpenSearch Service Serverless index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "529b3a43-50e1-4569-96b2-fd2bcfaa57fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-23 17:07:41,613] p29980 {utils.py:21} INFO - File CMP301_TrainDeploy_E1_20230607_SPEdited.json uploaded to multimodal-bucket-597703351594/multimodal/osi-embeddings-json/CMP301_TrainDeploy_E1_20230607_SPEdited.json.\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(f\"{Path(g.SLIDE_DECK).stem}.json\", bucket_name, g.BUCKET_EMB_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec9d6c-c2d6-4f7a-b8b1-cd1298fcf70d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 6. Monitoring OpenSearch Serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da97654-ce7e-4072-833c-cba530eadbe4",
   "metadata": {},
   "source": [
    "We can [monitor Amazon OpenSearch Serverless](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/monitoring-cloudwatch.html)\n",
    "and our [Ingestion OpenSearch pipelines](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/monitoring-pipeline-metrics.html) using Amazon CloudWatch, which collects raw data and processes it into readable, near real-time metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1abf0-d495-47af-9e92-4a29e1428125",
   "metadata": {},
   "source": [
    "Lets look at some metrics from OpenSearch Serverless. OpenSearch Serverless reports the metrics in the AWS/AOSS namespace. In this example, we are are looking at `ActiveCollection`, which indicates whether a collection is active. A value of *1* means that the collection is in an **ACTIVE** state. This value is emitted upon successful creation of a collection and remains *1* until you delete the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f98e8f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "client = boto3.client('cloudwatch')\n",
    "import pandas as pd    \n",
    "now = datetime.utcnow()\n",
    "start_time = now - timedelta(minutes=60)\n",
    "collection_id=host.split(\".\")[0]\n",
    "client_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "response = client.get_metric_statistics(\n",
    "    Namespace='AWS/AOSS',\n",
    "    MetricName='ActiveCollection',\n",
    "    Dimensions=[\n",
    "        {\n",
    "            'Name': 'CollectionName',\n",
    "            'Value': \"multimodal\"\n",
    "        },\n",
    "        {\n",
    "            'Name': 'ClientId',\n",
    "            'Value': client_id\n",
    "        },\n",
    "        {\n",
    "            'Name': 'CollectionId',\n",
    "            'Value': collection_id\n",
    "        }\n",
    "    ],\n",
    "    StartTime=start_time,\n",
    "    EndTime=now,\n",
    "    Period=600,\n",
    "    Statistics=['Maximum']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66c346aa-7839-45e1-a8b3-948308e72758",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a40d9\" style='display:inline'>\n",
       "  <caption>Maximum Number of Active Collections by Time</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a40d9_level0_col0\" class=\"col_heading level0 col0\" >Timestamp</th>\n",
       "      <th id=\"T_a40d9_level0_col1\" class=\"col_heading level0 col1\" >Maximum</th>\n",
       "      <th id=\"T_a40d9_level0_col2\" class=\"col_heading level0 col2\" >Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d9_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_a40d9_row0_col0\" class=\"data row0 col0\" >2024-01-23 16:07:00+00:00</td>\n",
       "      <td id=\"T_a40d9_row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
       "      <td id=\"T_a40d9_row0_col2\" class=\"data row0 col2\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d9_level0_row1\" class=\"row_heading level0 row1\" >5</th>\n",
       "      <td id=\"T_a40d9_row1_col0\" class=\"data row1 col0\" >2024-01-23 16:17:00+00:00</td>\n",
       "      <td id=\"T_a40d9_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_a40d9_row1_col2\" class=\"data row1 col2\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d9_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "      <td id=\"T_a40d9_row2_col0\" class=\"data row2 col0\" >2024-01-23 16:27:00+00:00</td>\n",
       "      <td id=\"T_a40d9_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "      <td id=\"T_a40d9_row2_col2\" class=\"data row2 col2\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d9_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "      <td id=\"T_a40d9_row3_col0\" class=\"data row3 col0\" >2024-01-23 16:37:00+00:00</td>\n",
       "      <td id=\"T_a40d9_row3_col1\" class=\"data row3 col1\" >1.000000</td>\n",
       "      <td id=\"T_a40d9_row3_col2\" class=\"data row3 col2\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d9_level0_row4\" class=\"row_heading level0 row4\" >2</th>\n",
       "      <td id=\"T_a40d9_row4_col0\" class=\"data row4 col0\" >2024-01-23 16:47:00+00:00</td>\n",
       "      <td id=\"T_a40d9_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_a40d9_row4_col2\" class=\"data row4 col2\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a40d9_level0_row5\" class=\"row_heading level0 row5\" >4</th>\n",
       "      <td id=\"T_a40d9_row5_col0\" class=\"data row5 col0\" >2024-01-23 16:57:00+00:00</td>\n",
       "      <td id=\"T_a40d9_row5_col1\" class=\"data row5 col1\" >1.000000</td>\n",
       "      <td id=\"T_a40d9_row5_col2\" class=\"data row5 col2\" >None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0d605b73d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.json_normalize(response['Datapoints'])\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df = df.sort_values(by='Timestamp')\n",
    "df.style.set_table_attributes(\"style='display:inline'\").set_caption('Maximum Number of Active Collections by Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd72aa1-231a-4b97-a6e0-696ee601bd83",
   "metadata": {},
   "source": [
    "Now lets look at some pipeline metrics. Pipeline metrics are published in the AWS/OSIS namespace. In this example were are looking at `recordsIn.count`, which is the ingress of records to a pipeline component. This metric applies to processors and sinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b40b95bf-d12a-4787-b268-9b0bb312684b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe_response = client.get_metric_statistics(\n",
    "    Namespace='AWS/OSIS',\n",
    "    MetricName='s3-pipeline.opensearch.recordsIn.count',\n",
    "    Dimensions=[\n",
    "        {\n",
    "            'Name': 'PipelineName',\n",
    "            'Value': \"multimodalpipeline\"\n",
    "        }\n",
    "    ],\n",
    "    StartTime=start_time,\n",
    "    EndTime=now,\n",
    "    Period=480,\n",
    "    Statistics=['Sum']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8eafc9c6-89a7-4a43-9822-be341a8b4a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_eb1c6\" style='display:inline'>\n",
       "  <caption>Maximum Number of Records In by Time</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eb1c6_level0_col0\" class=\"col_heading level0 col0\" >Timestamp</th>\n",
       "      <th id=\"T_eb1c6_level0_col1\" class=\"col_heading level0 col1\" >Sum</th>\n",
       "      <th id=\"T_eb1c6_level0_col2\" class=\"col_heading level0 col2\" >Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eb1c6_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_eb1c6_row0_col0\" class=\"data row0 col0\" >2024-01-23 16:07:00+00:00</td>\n",
       "      <td id=\"T_eb1c6_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_eb1c6_row0_col2\" class=\"data row0 col2\" >Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb1c6_level0_row1\" class=\"row_heading level0 row1\" >4</th>\n",
       "      <td id=\"T_eb1c6_row1_col0\" class=\"data row1 col0\" >2024-01-23 16:15:00+00:00</td>\n",
       "      <td id=\"T_eb1c6_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_eb1c6_row1_col2\" class=\"data row1 col2\" >Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb1c6_level0_row2\" class=\"row_heading level0 row2\" >7</th>\n",
       "      <td id=\"T_eb1c6_row2_col0\" class=\"data row2 col0\" >2024-01-23 16:23:00+00:00</td>\n",
       "      <td id=\"T_eb1c6_row2_col1\" class=\"data row2 col1\" >31.000000</td>\n",
       "      <td id=\"T_eb1c6_row2_col2\" class=\"data row2 col2\" >Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb1c6_level0_row3\" class=\"row_heading level0 row3\" >6</th>\n",
       "      <td id=\"T_eb1c6_row3_col0\" class=\"data row3 col0\" >2024-01-23 16:31:00+00:00</td>\n",
       "      <td id=\"T_eb1c6_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_eb1c6_row3_col2\" class=\"data row3 col2\" >Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb1c6_level0_row4\" class=\"row_heading level0 row4\" >0</th>\n",
       "      <td id=\"T_eb1c6_row4_col0\" class=\"data row4 col0\" >2024-01-23 16:39:00+00:00</td>\n",
       "      <td id=\"T_eb1c6_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_eb1c6_row4_col2\" class=\"data row4 col2\" >Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb1c6_level0_row5\" class=\"row_heading level0 row5\" >2</th>\n",
       "      <td id=\"T_eb1c6_row5_col0\" class=\"data row5 col0\" >2024-01-23 16:47:00+00:00</td>\n",
       "      <td id=\"T_eb1c6_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
       "      <td id=\"T_eb1c6_row5_col2\" class=\"data row5 col2\" >Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb1c6_level0_row6\" class=\"row_heading level0 row6\" >5</th>\n",
       "      <td id=\"T_eb1c6_row6_col0\" class=\"data row6 col0\" >2024-01-23 16:55:00+00:00</td>\n",
       "      <td id=\"T_eb1c6_row6_col1\" class=\"data row6 col1\" >31.000000</td>\n",
       "      <td id=\"T_eb1c6_row6_col2\" class=\"data row6 col2\" >Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eb1c6_level0_row7\" class=\"row_heading level0 row7\" >3</th>\n",
       "      <td id=\"T_eb1c6_row7_col0\" class=\"data row7 col0\" >2024-01-23 17:03:00+00:00</td>\n",
       "      <td id=\"T_eb1c6_row7_col1\" class=\"data row7 col1\" >0.000000</td>\n",
       "      <td id=\"T_eb1c6_row7_col2\" class=\"data row7 col2\" >Count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0d605338b0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.json_normalize(pipe_response['Datapoints'])\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df = df.sort_values(by='Timestamp')\n",
    "df.style.set_table_attributes(\"style='display:inline'\").set_caption('Maximum Number of Records In by Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3466f-d871-41ea-89cc-e326af6f185c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
