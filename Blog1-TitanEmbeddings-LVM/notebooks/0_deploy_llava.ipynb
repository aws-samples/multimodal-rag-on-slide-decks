{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78017671-e161-41cc-b662-b16a13013ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deploy LLaVA-v1.5-7B model on Amazon SageMaker\n",
    "\n",
    "***This notebook works best with the `conda_python3` kernel on a `ml.t3.large` machine***.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we download the [LLaVA-v1.5-7B](https://huggingface.co/anymodality/llava-v1.5-7b) and deploy it on SageMaker. We use the `huggingface-pytorch-inference` container and deploy this model on a `ml.g5.xlarge` instance type. \n",
    "\n",
    "The downloaded model files are archived into a `model.tar.gz` file that is uploaded to the default SageMaker S3 bucket. The `inference.py` file is overwritten with a [`llava_inference.py`](./llava_inference.py) file that has code to run inference on an image stored in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c5a2e-9856-4006-b424-5137f634709f",
   "metadata": {},
   "source": [
    "## Step 1. Setup\n",
    "\n",
    "Install the required Python packages and import the relevant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b2a533-1e0d-4aa6-a455-a7e9e0dcf1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub==0.19.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.19.4)\n",
      "Requirement already satisfied: sagemaker==2.199.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.199.0)\n",
      "Requirement already satisfied: pypdfium2==4.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.24.0)\n",
      "Requirement already satisfied: httplib2==0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.19.0)\n",
      "Requirement already satisfied: langchain==0.0.340 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.0.340)\n",
      "Requirement already satisfied: requests==2.31.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: pandas==1.5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: boto3==1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.34.0)\n",
      "Requirement already satisfied: botocore==1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.34.0)\n",
      "Requirement already satisfied: opensearch-py==2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.4.2)\n",
      "Requirement already satisfied: numexpr==2.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.8.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (23.2)\n",
      "Requirement already satisfied: docutils in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.16)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (4.25.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (6.8.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.7.5)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (4.19.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (3.11.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: urllib3<1.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (1.26.18)\n",
      "Requirement already satisfied: uvicorn==0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.22.0)\n",
      "Requirement already satisfied: fastapi==0.95.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (0.95.2)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (6.1.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker==2.199.0->-r requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httplib2==0.19.0->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (0.0.79)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (1.10.13)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.340->-r requirements.txt (line 5)) (8.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0->-r requirements.txt (line 6)) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests==2.31.0->-r requirements.txt (line 6)) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 7)) (2023.3.post1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.34.0->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3==1.34.0->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py==2.4.2->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fastapi==0.95.2->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.27.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn==0.22.0->sagemaker==2.199.0->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn==0.22.0->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340->-r requirements.txt (line 5)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340->-r requirements.txt (line 5)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.340->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.340->-r requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340->-r requirements.txt (line 5)) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.199.0->-r requirements.txt (line 2)) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.340->-r requirements.txt (line 5)) (2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.340->-r requirements.txt (line 5)) (3.0.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from docker->sagemaker==2.199.0->-r requirements.txt (line 2)) (1.6.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker==2.199.0->-r requirements.txt (line 2)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.10.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker==2.199.0->-r requirements.txt (line 2)) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker==2.199.0->-r requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from schema->sagemaker==2.199.0->-r requirements.txt (line 2)) (21.6.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340->-r requirements.txt (line 5)) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6340b289-30e4-466d-a36c-4a604cf4c063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-09 21:20:50,380] p15034 {credentials.py:1075} INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import sagemaker\n",
    "import globals as g\n",
    "import requests as req\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from utils import get_bucket_name\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker import get_execution_role\n",
    "from huggingface_hub import snapshot_download\n",
    "from sagemaker.huggingface.model import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1e19b6-b40e-4046-ad16-c04fef30f203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33mGlobal variables used throughout the code.\u001b[39;49;00m\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# model deployment\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "HF_MODEL_ID = \u001b[33m\"\u001b[39;49;00m\u001b[33manymodality/llava-v1.5-13b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "HF_MODEL_ID: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33manymodality/llava-v1.5-7b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "HF_TASK: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mquestion-answering\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "TRANSFORMERS_VERSION: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33m4.28.1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "PYTORCH_VERSION: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33m2.0.0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "PYTHON_VERSION: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mpy310\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# S3 bucket strucutre, we use the default sagemaker bucket in the current region\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# BUCKET_NAME: str = sagemaker.Session().default_bucket()\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "BUCKET_PREFIX: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mmultimodal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "BUCKET_EMB_PREFIX: \u001b[36mstr\u001b[39;49;00m = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mBUCKET_PREFIX\u001b[33m}\u001b[39;49;00m\u001b[33m/osi-embeddings-json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "BUCKET_IMG_PREFIX: \u001b[36mstr\u001b[39;49;00m = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mBUCKET_PREFIX\u001b[33m}\u001b[39;49;00m\u001b[33m/img\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Amazon Titan multimodal model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "AWS_REGION: \u001b[36mstr\u001b[39;49;00m = boto3.Session().region_name\u001b[37m\u001b[39;49;00m\n",
      "FMC_URL: \u001b[36mstr\u001b[39;49;00m = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://bedrock-runtime.\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mAWS_REGION\u001b[33m}\u001b[39;49;00m\u001b[33m.amazonaws.com\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "FMC_MODEL_ID: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mamazon.titan-embed-image-v1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "ACCEPT_ENCODING: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "CONTENT_ENCODING: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# model.tar.gz path in S3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# S3_MODEL_URI: str = os.path.join(\"s3://\", BUCKET_NAME, BUCKET_PREFIX, os.path.basename(HF_MODEL_ID))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Amazon OpenSearch Service Serverless\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "OS_SERVICE: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33maoss\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# local files and folder structure\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "IMAGE_DIR: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mimg\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "IMAGE_FILE_EXTN: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33m.jpg\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "B64_ENCODED_IMAGES_DIR: \u001b[36mstr\u001b[39;49;00m = os.path.join(IMAGE_DIR, \u001b[33m\"\u001b[39;49;00m\u001b[33mb64_images\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "ENDPOINT_FILENAME: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mendpoint.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# this is the slide deck to which we will be talking to. Replace with your slide deck's URL to analyze a different deck\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "SLIDE_DECK: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://d1.awsstatic.com/events/Summits/torsummit2023/CMP301_TrainDeploy_E1_20230607_SPEdited.pdf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# AWS CloudFormation stack that created the resources for this blog post including this notebook\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# if a different name is used while creating the CloudFormation stack then change this to match the name you used\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "CFN_STACK_NAME: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mmultimodal-stack\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "# global constants\n",
    "!pygmentize globals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea3c3e5f-e7a0-40bb-af06-4724da6a47a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "805b58d5-a60c-408e-b07a-382d97c9930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name: str = get_bucket_name(g.CFN_STACK_NAME)\n",
    "s3_model_uri: str = os.path.join(\"s3://\", bucket_name, g.BUCKET_PREFIX, os.path.basename(g.HF_MODEL_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d5b378-ee60-453b-b410-c372ab863a24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-09 21:20:52,324] p15034 {2234532258.py:3} INFO - HF_MODEL_ID=anymodality/llava-v1.5-7b, model_dir=llava-v1.5-7b, model_tar_gz_path=/home/ec2-user/SageMaker/multimodal-rag-on-slide-decks/Blog1-TitanEmbeddings-LVM/model_llava-v1.5-7b.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_dir: str = g.HF_MODEL_ID.split(\"/\")[-1]\n",
    "model_tar_gz_path: str = os.path.join(os.path.dirname(os.getcwd()), f\"model_{model_dir}.tar.gz\")\n",
    "logger.info(f\"HF_MODEL_ID={g.HF_MODEL_ID}, model_dir={model_dir}, model_tar_gz_path={model_tar_gz_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3419b4-9b47-4e40-a985-90b01dc7ab4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Prepare the `model.tar.gz`\n",
    "\n",
    "1. Download the model files from HuggingFace.\n",
    "\n",
    "1. Update the `inference.py` with [`llava_inference.py`](./llava_inference.py)\n",
    "\n",
    "1. Zip the model directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be9a58-a0f4-4489-a041-c68ace7f164e",
   "metadata": {},
   "source": [
    "Download the model files. **This takes about 5 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55eb9bd4-b287-4627-847f-c29ac48c0c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e54332a5bbc47b8a6d7df6dc64d26a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a047b5b417134a1282a9ebee64324d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1374576a42548fcadd43df7d81cb9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c0d37ab55d484095c1fdde26b414f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deploy_llava.ipynb:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb429e898e04f07821bc93bfd16e655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "code/inference.py:   0%|          | 0.00/3.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa20b7e36b904a6faeb1e73c26c087b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ee442de6454f17b76b03607e7215a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/27.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1a3352d46343788bc89fd2ad2470f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc5274f2bec4e1ebffe6747f44253d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "code/requirements.txt:   0%|          | 0.00/55.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350cce859fc7407a89e6bd8abff20a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce611392cf94abab0a4b568683243a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e14a3c07ae469187f55b7fdb883dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50ce53051d242df93e9cc3647f1834d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e9ac49a71340ba800191598ceac458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 32.8 s, total: 49.8 s\n",
      "Wall time: 3min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/multimodal-rag-on-slide-decks/Blog1-TitanEmbeddings-LVM/llava-v1.5-7b'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_path: str = os.path.join(os.path.dirname(os.getcwd()), model_dir)\n",
    "Path(model_path).mkdir(exist_ok=True)\n",
    "# Download model from Hugging Face into model_dir\n",
    "snapshot_download(g.HF_MODEL_ID, local_dir=model_path, local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ddecbd-13e1-40f4-ab41-799b86c45971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/multimodal-rag-on-slide-decks/Blog1-TitanEmbeddings-LVM/llava-v1.5-7b/code/inference.py'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update the inference script\n",
    "inf_dest: str = os.path.join(model_path, 'code', 'inference.py')\n",
    "shutil.copyfile(\"llava_inference.py\", inf_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da211c93-6772-465d-ba6c-5da473075681",
   "metadata": {},
   "source": [
    "Create a .tar.gz file. **This step takes about 10 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d877fefd-0d85-4f7e-add0-992977863f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/multimodal-rag-on-slide-decks/Blog1-TitanEmbeddings-LVM/notebooks\n",
      "CPU times: user 9.15 s, sys: 1.01 s, total: 10.2 s\n",
      "Wall time: 10min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create SageMaker model.tar.gz artifact\n",
    "!cd {model_path};tar -cf {model_tar_gz_path} --use-compress-program=pigz *;cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1970ca9-2935-4b58-8256-14ed675d08b7",
   "metadata": {},
   "source": [
    "Upload the model.tar.gz to S3. **This steps takes about 3 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47dd39a8-a2ec-474b-936b-8e507bb994da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-09 21:37:41,602] p15034 {<timed exec>:3} INFO - model uploaded to: s3://multimodal-bucket-731963050968/multimodal/llava-v1.5-7b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 2min 4s, total: 3min 52s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# upload model.tar.gz to s3\n",
    "S3Uploader.upload(local_path=model_tar_gz_path, desired_s3_uri=s3_model_uri)\n",
    "logger.info(f\"model uploaded to: {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b9d37-cabd-48a0-8466-8739d978f62f",
   "metadata": {},
   "source": [
    "## Step 3: Deploy the model on SageMaker\n",
    "\n",
    "Here we deploy the model on SageMaker. We use the [HuggingFaceModel](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html) class from the SageMaker SDK. **This steps takes about 10 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c801a72-6e60-4e7b-9e7a-6033ada82d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-09 21:37:41,618] p15034 {<timed exec>:7} INFO - going to deploy anymodality/llava-v1.5-7b model, model_data=s3://multimodal-bucket-731963050968/multimodal/llava-v1.5-7b/model_llava-v1.5-7b.tar.gz, instance_type=ml.g5.xlarge, instance_count=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-09 21:37:42,257] p15034 {session.py:3645} INFO - Creating model with name: huggingface-pytorch-inference-2024-01-09-21-37-42-256\n",
      "[2024-01-09 21:37:42,858] p15034 {session.py:5321} INFO - Creating endpoint-config with name huggingface-pytorch-inference-2024-01-09-21-37-42-858\n",
      "[2024-01-09 21:37:43,173] p15034 {session.py:4223} INFO - Creating endpoint with name huggingface-pytorch-inference-2024-01-09-21-37-42-858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-09 21:45:15,145] p15034 {<timed exec>:23} INFO - finished deploying model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 507 ms, sys: 11.5 ms, total: 518 ms\n",
      "Wall time: 7min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set the env vars for the model\n",
    "config: Dict = dict(HF_TASK=g.HF_TASK)\n",
    "\n",
    "model_data: str = os.path.join(s3_model_uri, f\"model_{os.path.basename(g.HF_MODEL_ID)}.tar.gz\")\n",
    "instance_type: str = \"ml.g5.xlarge\"\n",
    "instance_count: int = 1\n",
    "logger.info(f\"going to deploy {g.HF_MODEL_ID} model, model_data={model_data}, instance_type={instance_type}, instance_count={instance_count}\")\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=model_data,   \n",
    "   role=get_execution_role(),                                  \n",
    "   transformers_version=g.TRANSFORMERS_VERSION,  \n",
    "   pytorch_version=g.PYTORCH_VERSION,            \n",
    "   py_version=g.PYTHON_VERSION,                \n",
    "   model_server_workers=1,\n",
    "   env=config\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(initial_instance_count=instance_count,\n",
    "                                     instance_type=instance_type)\n",
    "logger.info(f\"finished deploying model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e45f06-3344-41f6-acdd-2a7ef13292eb",
   "metadata": {},
   "source": [
    "The [HuggingFaceModel](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html) encapsulated several defaults, lets examine the parameters for the deployed model to review the model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f73749-8c41-4336-8e1f-6ea39d8fe938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-09 21:45:15,162] p15034 {985546471.py:1} INFO - model info -> {'framework_version': '4.28.1', 'pytorch_version': '2.0.0', 'tensorflow_version': None, 'py_version': 'py310', 'model_data': 's3://multimodal-bucket-731963050968/multimodal/llava-v1.5-7b/model_llava-v1.5-7b.tar.gz', 'image_uri': None, 'predictor_cls': <class 'sagemaker.huggingface.model.HuggingFacePredictor'>, 'name': 'huggingface-pytorch-inference-2024-01-09-21-37-42-256', '_base_name': 'huggingface-pytorch-inference', 'sagemaker_session': <sagemaker.session.Session object at 0x7f77fc431c60>, 'algorithm_arn': None, 'model_package_arn': None, '_sagemaker_config': {}, 'role': 'arn:aws:iam::731963050968:role/multimodal-stack-SMExecutionRole-JpUn1cG4CQ5G', 'vpc_config': None, 'endpoint_name': 'huggingface-pytorch-inference-2024-01-09-21-37-42-858', '_is_compiled_model': False, '_compilation_job_name': None, '_is_edge_packaged_model': False, 'inference_recommender_job_results': None, 'inference_recommendations': None, '_enable_network_isolation': False, 'env': {'HF_TASK': 'question-answering'}, 'model_kms_key': None, 'image_config': None, 'entry_point': None, 'source_dir': None, 'dependencies': [], 'git_config': None, 'container_log_level': 20, 'bucket': None, 'key_prefix': None, 'uploaded_code': None, 'repacked_model_data': None, 'mode': None, 'modes': {}, 'serve_settings': None, 'resources': None, 'content_types': None, 'response_types': None, 'accept_eula': None, 'model_server_workers': 1}\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"model info -> {vars(huggingface_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd383428-56be-4109-a12a-fc456c675f8b",
   "metadata": {},
   "source": [
    "Save the name of the deployed endpoint so that the other notebooks can create a [`Predictor`](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html) and use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34d8d30-ed38-4bf9-b894-e1a4590ed432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = Path(g.ENDPOINT_FILENAME).write_text(predictor.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
