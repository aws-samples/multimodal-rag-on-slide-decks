{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbb582e-d21a-41cf-b45e-e2f462424ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data ingestion\n",
    "\n",
    "***This notebook works best with the `conda_python3` on the `ml.t3.large` instance***.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we download the images corresponding to each slide deck in the [sample dataset](../qa.jsonl), convert them into embeddings and then ingest these embeddings into a vector database i.e. [Amazon OpenSearch Service Serverless](https://aws.amazon.com/opensearch-service/features/serverless/).\n",
    "\n",
    "1. We use the [Amazon Titan Multiodal Embeddings](https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-titan-multimodal-embeddings-model-bedrock/) model to convert the images into embeddings.\n",
    "\n",
    "1. The embeddings are then ingested into OpenSearch Service Serverless using the [Amazon OpenSearch Ingestion](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/ingestion.html) pipeline. The embeddings are uploaded into an S3 bucket and that triggers the OpenSearch Ingestion pipeline which ingests the data into an OpenSearch Serverless index.\n",
    "\n",
    "1. The OpenSearch Service Serverless Collection is created via the AWS CloudFormation stack for this blog post.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a62857-6a66-44db-9d92-3df221c6bd21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1. Setup\n",
    "\n",
    "Install the required Python packages and import the relevant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f869e5d-8e4b-4d44-9e2a-4f20b77b92d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beda5d30-06f7-44a6-9b1d-8ac27fb93cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import codecs\n",
    "import base64\n",
    "import logging\n",
    "import botocore\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import globals as g\n",
    "import requests as req\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from utils import upload_to_s3, get_cfn_outputs, get_bucket_name, download_image_from_url, encode_image_to_base64\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e709ae-facf-489d-af69-c3a4373ab1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock = boto3.client(service_name=\"bedrock-runtime\", endpoint_url=g.TITAN_URL)\n",
    "bucket_name: str = get_bucket_name(g.CFN_STACK_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b57d2df-d685-43da-a1b4-4212ec4772b2",
   "metadata": {},
   "source": [
    "## Step 2. Create the OpenSearch Service Serverless index\n",
    "\n",
    "**This step is only required until we get support creating an OpenSearch Service Serverless index via AWS CloudFormation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0acd94-ad70-4d98-95ca-fb7ea5eaa05b",
   "metadata": {},
   "source": [
    "Get the name of the OpenSearch Service Serverless collection endpoint and index name from the CloudFormation stack outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e8ed38-2512-428f-a53c-b666466d2e70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-17 18:22:48,790] p30904 {725157277.py:5} INFO - opensearchhost=7uiiz7d87b3q8u2kfmtd.us-east-1.aoss.amazonaws.com, index=blog3slides-app1\n"
     ]
    }
   ],
   "source": [
    "outputs = get_cfn_outputs(g.CFN_STACK_NAME)\n",
    "host = outputs['MultimodalCollectionEndpoint'].split('//')[1]\n",
    "index_name = outputs['OpenSearchIndexName']\n",
    "logger.info(f\"opensearchhost={host}, index={index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953454d9-d335-4a2a-bbcb-852ea95a1de0",
   "metadata": {},
   "source": [
    "We use the OpenSearch client to create an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5b2b2e-3c41-4ccd-8260-eb7caf247d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-17 18:22:53,763] p30904 {credentials.py:1075} INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, g.AWS_REGION, g.OS_SERVICE)\n",
    "\n",
    "os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56121d-441e-4d08-8375-78380ae380e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "The structure of the index is important. Note the following about the index.\n",
    "\n",
    "1. The index is a (k-NN](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/knn.html) index so that we can do a vector similarity search in this index.\n",
    "\n",
    "1. The vector dimension is 1,024 which corresponds to the output dimension of the Amazon Titan Multimodal Embeddings model that we are using.\n",
    "\n",
    "1. The index uses the [`Hierarchical Navigable Small World (HNSW)`](https://aws.amazon.com/blogs/big-data/choose-the-k-nn-algorithm-for-your-billion-scale-use-case-with-opensearch/) algorithm for similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d77228-8db8-4302-a3f9-77cba53a7061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-17 18:23:09,969] p30904 {base.py:259} INFO - PUT https://7uiiz7d87b3q8u2kfmtd.us-east-1.aoss.amazonaws.com:443/blog3slides-app1 [status:200 request:0.558s]\n",
      "[2024-07-17 18:23:09,971] p30904 {3614055036.py:70} INFO - response received for the create index -> {'acknowledged': True, 'shards_acknowledged': True, 'index': 'blog3slides-app1'}\n"
     ]
    }
   ],
   "source": [
    "index_body = \"\"\"\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index.knn\": true\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"vector_embedding\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 1024,\n",
    "        \"method\": {\n",
    "          \"name\": \"hnsw\",\n",
    "          \"engine\": \"nmslib\",\n",
    "          \"parameters\": {}\n",
    "        }\n",
    "      },\n",
    "      \"image_url\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "       \"metadata\": { \n",
    "        \"properties\" :\n",
    "          {\n",
    "            \"deck_name\" : {\n",
    "              \"type\" : \"text\"\n",
    "            },\n",
    "            \"deck_url\" : {\n",
    "              \"type\" : \"text\"\n",
    "            }\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# We would get an index already exists exception if the index already exists, and that is fine.\n",
    "index_body = json.loads(index_body)\n",
    "try:\n",
    "    response = os_client.indices.create(index_name, body=index_body)\n",
    "    logger.info(f\"response received for the create index -> {response}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"error in creating index={index_name}, exception={e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945830f-86b3-43f3-9d28-a75ae3058a8a",
   "metadata": {},
   "source": [
    "## Step 3: Download images locally, get embeddings for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b38cd73-0bce-4313-bc2b-d9cc33a3bb79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_multimodal_embeddings(bedrock: botocore.client, image: str) -> np.ndarray:\n",
    "    body = json.dumps(dict(inputImage=image))\n",
    "    try:\n",
    "        response = bedrock.invoke_model(\n",
    "            body=body, modelId=g.FMC_MODEL_ID, accept=g.ACCEPT_ENCODING, contentType=g.CONTENT_ENCODING\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        embeddings = np.array([response_body.get(\"embedding\")]).astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"exception while image(truncated)={image[:10]}, exception={e}\")\n",
    "        embeddings = None\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cda3cd-cd14-479c-8feb-e7cd3a3292bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(g.IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(g.B64_ENCODED_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(g.EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "cols = ['url']\n",
    "with jsonlines.open('qa.jsonl') as f:\n",
    "    for line in f.iter():\n",
    "        embeddings_list = []\n",
    "        deck_name = line['deck_name']\n",
    "        deck_url = line['deck_url']\n",
    "        img_df = pd.DataFrame(line['image_urls'], columns=cols)\n",
    "        for ind, row in img_df.iterrows():\n",
    "            img_url = row['url']\n",
    "            img_path = download_image_from_url(img_url, g.IMAGE_DIR)\n",
    "            if img_path != \"\":\n",
    "                b64_img_path = encode_image_to_base64(img_path)\n",
    "\n",
    "                logger.info(f\"going to convert {img_url} into embeddings\")\n",
    "\n",
    "                # read the file, MAX image size supported is 2048 * 2048 pixels\n",
    "                with open(b64_img_path, \"rb\") as image_file:\n",
    "                    input_image_b64 = image_file.read().decode('utf-8')\n",
    "\n",
    "                # make a call to Bedrock to get the embeddings corresponding to\n",
    "                # this image's base64 data\n",
    "                st = time.perf_counter()\n",
    "                embeddings = get_multimodal_embeddings(bedrock, input_image_b64)\n",
    "                if embeddings is None:\n",
    "                    logger.error(f\"error creating multimodal embeddings for {img_url}\")\n",
    "                    continue\n",
    "                latency = time.perf_counter() - st\n",
    "                logger.info(f\"successfully converted {img_url} to embeddings in {latency:.2f} seconds\")\n",
    "\n",
    "                # convert the data we want to ingest for this image into a JSON, this include the metadata as well\n",
    "                # the metadata can be used later as part of hybrid search from the vector db\n",
    "                data = {\n",
    "                    \"image_url\": img_url,\n",
    "                    \"metadata\": {\n",
    "                      \"deck_name\": deck_name,\n",
    "                      \"deck_url\": deck_url\n",
    "                    },\n",
    "                    \"vector_embedding\": embeddings[0].tolist()\n",
    "                  }\n",
    "\n",
    "                embeddings_list.append(data)\n",
    "                logger.info(f\"appended json data corresponding to {img_url}\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        if len(embeddings_list) > 0:\n",
    "            fpath: str = f\"{g.EMBEDDINGS_DIR}/{deck_name}.json\"\n",
    "            json.dump(embeddings_list, codecs.open(fpath, 'w', encoding='utf-8'), \n",
    "                      separators=(',', ':'), \n",
    "                      sort_keys=True, \n",
    "                      indent=4)\n",
    "            logger.info(f\"saved multimodal embeddings for deck {deck_name} in {fpath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a809a-8ae8-4e47-9daa-aa92ee1c9a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_file_list: List = glob.glob(os.path.join(g.EMBEDDINGS_DIR, \"*.json\"))\n",
    "logger.info(f\"there are {len(embedding_file_list)} embeddings\")\n",
    "for embedding_file_path in embedding_file_list:\n",
    "    upload_to_s3(embedding_file_path, bucket_name, g.BUCKET_EMB_PREFIX)\n",
    "    logger.info(f\"uploaded embeddings for deck {os.path.basename(embedding_file_path)} to S3 bucket {bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4218503-ec1c-4a86-b4db-01b742584ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
