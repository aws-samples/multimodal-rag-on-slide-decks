{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60a883d-0982-4d26-84c3-f5a9b917758f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data ingestion\n",
    "\n",
    "***This notebook works best with the `conda_python3` on the `ml.t3.large` instance***.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we download the images corresponding to each slide deck in the [sample dataset](../qa.jsonl), convert them into embeddings and then ingest these embeddings into a vector database i.e. [Amazon OpenSearch Service Serverless](https://aws.amazon.com/opensearch-service/features/serverless/).\n",
    "\n",
    "1. We use the [Anthropicâ€™s Claude 3 Sonnet foundation model](https://aws.amazon.com/about-aws/whats-new/2024/03/anthropics-claude-3-sonnet-model-amazon-bedrock/) available on Bedrock to convert image to text.\n",
    "\n",
    "1. We then use [Amazon Titan Text Embeddings model](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html) to convert the text into embeddings.\n",
    "\n",
    "1. The embeddings are then ingested into OpenSearch Service Serverless using the [Amazon OpenSearch Ingestion pipeline](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/ingestion.html). We ingest the embeddings into an OpenSearch Serverless index via the OpenSearch Ingestion API.\n",
    "\n",
    "1. The OpenSearch Service Serverless Collection is created via the AWS CloudFormation stack for this blog post.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38f56b-f7fc-4544-acaa-66d60000518c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "Install the required Python packages and import the relevant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7fb2d-f72e-4290-b5af-7b41f0dd8091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e734d3-9341-4fb4-a2cc-e75e8dcaa820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ray\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import codecs\n",
    "import base64\n",
    "import logging\n",
    "import botocore\n",
    "import sagemaker\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import globals as g\n",
    "import requests as req\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from requests_auth_aws_sigv4 import AWSSigV4\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from utils import get_cfn_outputs, get_bucket_name, download_image_files_from_s3, get_text_embedding\n",
    "from utils import download_image_from_url, encode_image_to_base64, get_img_desc\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796e9624-05d1-4942-a255-3eb4b9e252d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=g.AWS_REGION, endpoint_url=g.TITAN_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd845a-e674-4b3c-80c4-0e0f18146fbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Create the OpenSearch Service Serverless index\n",
    "\n",
    "**This step is only required until we get support creating an OpenSearch Service Serverless index via AWS CloudFormation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b444876f-359c-401e-b006-f3e48b47286e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-18 17:02:29,213] p6048 {3829838013.py:5} INFO - opensearchhost=7uiiz7d87b3q8u2kfmtd.us-east-1.aoss.amazonaws.com, index=blog3slides-app2\n"
     ]
    }
   ],
   "source": [
    "outputs = get_cfn_outputs(g.CFN_STACK_NAME)\n",
    "host = outputs['MultimodalCollectionEndpoint'].split('//')[1]\n",
    "index_name = outputs['OpenSearchIndexName']\n",
    "logger.info(f\"opensearchhost={host}, index={index_name}\")\n",
    "\n",
    "osi_endpoint = f\"https://{outputs['OpenSearchPipelineEndpoint']}/data/ingest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7860e10-544b-404d-b670-f741cf8a9093",
   "metadata": {
    "tags": []
   },
   "source": [
    "We use the OpenSearch client to create an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8190211-86e0-4644-92c3-b390443bcdaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, g.AWS_REGION, g.OS_SERVICE)\n",
    "\n",
    "os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef62595-dd52-4f1a-b4a2-6cd780707103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-17 19:52:41,113] p31527 {base.py:259} INFO - PUT https://7uiiz7d87b3q8u2kfmtd.us-east-1.aoss.amazonaws.com:443/blog3slides-app2 [status:200 request:0.566s]\n",
      "[2024-07-17 19:52:41,114] p31527 {3324873869.py:43} INFO - response received for the create index -> {'acknowledged': True, 'shards_acknowledged': True, 'index': 'blog3slides-app2'}\n"
     ]
    }
   ],
   "source": [
    "index_body = \"\"\"\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index.knn\": true\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"vector_embedding\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 1536,\n",
    "        \"method\": {\n",
    "          \"name\": \"hnsw\",\n",
    "          \"engine\": \"nmslib\",\n",
    "          \"parameters\": {}\n",
    "        }\n",
    "      },\n",
    "      \"image_url\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"slide_text\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "       \"metadata\": { \n",
    "        \"properties\" :\n",
    "          {\n",
    "            \"deck_name\" : {\n",
    "              \"type\" : \"text\"\n",
    "            },\n",
    "            \"deck_url\" : {\n",
    "              \"type\" : \"text\"\n",
    "            }\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# We would get an index already exists exception if the index already exists, and that is fine.\n",
    "index_body = json.loads(index_body)\n",
    "try:\n",
    "    response = os_client.indices.create(index_name, body=index_body)\n",
    "    logger.info(f\"response received for the create index -> {response}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"error in creating index={index_name}, exception={e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf952fa6-a80d-416b-9001-b3aa3bceff06",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Download images locally, get embeddings and ingest into OSI pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9143ba81-69bd-4869-a8bc-d20cbdd3f5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please provide a detailed description of the image. Identify and describe any tables, charts, or other visual elements present, including the specific data or information contained within them. Provide as much detail as possible about the content within the slide. Your response should be extremely detailed and data oriented. Be completely accurate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Please provide a detailed description of the image. Identify and describe any tables, charts, or other visual elements present, including the specific data or information contained within them. Provide as much detail as possible about the content within the slide. Your response should be extremely detailed and data oriented. Be completely accurate.\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd22e75-4bf8-458c-bc89-b99e919125b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(g.IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(g.B64_ENCODED_IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "cols = ['url']\n",
    "with jsonlines.open('qa.jsonl') as f:\n",
    "    for line in f.iter():\n",
    "        deck_name = line['deck_name']\n",
    "        deck_url = line['deck_url']\n",
    "        img_df = pd.DataFrame(line['image_urls'], columns=cols)\n",
    "        for ind, row in img_df.iterrows():\n",
    "            img_url = row['url']\n",
    "            img_path = download_image_from_url(img_url, g.IMAGE_DIR)\n",
    "            if img_path != \"\":\n",
    "                try:\n",
    "                    b64_img_path = encode_image_to_base64(img_path)\n",
    "\n",
    "                    logger.info(f\"going to convert {img_url} into embeddings\")\n",
    "                    resp_text = get_img_desc(bedrock, b64_img_path, prompt)\n",
    "                    embedding = get_text_embedding(bedrock, resp_text, g.TITAN_MODEL_ID)\n",
    "\n",
    "                    # convert the data we want to ingest for this image into a JSON, this include the metadata as well\n",
    "                    # the metadata can be used later as part of hybrid search from the vector db\n",
    "                    data = json.dumps([{\n",
    "                        \"image_url\": img_url,\n",
    "                        \"slide_text\": resp_text,\n",
    "                        \"metadata\": {\n",
    "                          \"deck_name\": deck_name,\n",
    "                          \"deck_url\": deck_url\n",
    "                        },\n",
    "                        \"vector_embedding\": embedding\n",
    "                      }])\n",
    "\n",
    "                    r = req.request(\n",
    "                    method='POST', \n",
    "                    url=osi_endpoint, \n",
    "                    data=data,\n",
    "                    auth=AWSSigV4('osis'))\n",
    "\n",
    "                    logger.info(\"Ingesting data into pipeline\")\n",
    "                    logger.info(f\"Response: {img_url} - {r.text}\")\n",
    "                except:\n",
    "                    logger.info(f\"Error occurred processing image in deck {deck_name}: {img_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0593d2-3ae6-428a-a371-e65e13952169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
